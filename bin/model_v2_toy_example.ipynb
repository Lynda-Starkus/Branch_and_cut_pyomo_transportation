{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import multivariate_normal\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "# Generic synthetic demand\n",
    "class SyntheticDemand:\n",
    "\n",
    "    def __init__(self, K, O, D, G):\n",
    "\n",
    "        self.Lag = K\n",
    "        self.Nr_origins = O\n",
    "        self.Nr_destionations = D\n",
    "\n",
    "        self.Grid_dim = G\n",
    "\n",
    "        g = G / 100.\n",
    "\n",
    "        x, y = np.mgrid[0:G:g, 0:G:g]\n",
    "        pos = np.empty(x.shape + (2,))\n",
    "        pos[:, :, 0] = x\n",
    "        pos[:, :, 1] = y\n",
    "\n",
    "        self.Grid = pos\n",
    "\n",
    "        self.coordinates = [(self.Grid[k, r])\n",
    "                            for k in range(0, len(self.Grid))\n",
    "                            for r in range(self.Grid.shape[0])]\n",
    "\n",
    "        self.create_origins()\n",
    "        self.create_destinations()\n",
    "\n",
    "    def create_origins(self):\n",
    "        self.Origins = []\n",
    "\n",
    "        np.random.seed(None)\n",
    "        for _ in range(self.Nr_origins):\n",
    "            x = np.random.randint(0, self.Grid_dim)\n",
    "            y = np.random.randint(0, self.Grid_dim)\n",
    "            self.Origins.append(np.array([x, y]))\n",
    "\n",
    "    def create_destinations(self):\n",
    "        self.Destinations = []\n",
    "\n",
    "        np.random.seed(None)\n",
    "        for _ in range(self.Nr_destionations):\n",
    "            x = np.random.randint(0, self.Grid_dim)\n",
    "            y = np.random.randint(0, self.Grid_dim)\n",
    "            self.Destinations.append(np.array([x, y]))\n",
    "\n",
    "    def create_prob_distribution(self, c, plt_opt):\n",
    "        if c == \"O\":\n",
    "            centres = copy.copy(self.Origins)\n",
    "        elif c == \"D\":\n",
    "            centres = copy.copy(self.Destinations)\n",
    "        else:\n",
    "            print(\"Wrong argument!\")\n",
    "            return\n",
    "\n",
    "        pdf = []\n",
    "        pdf_tot = np.zeros((self.Grid[:, :, 0].shape[0], self.Grid[:, :, 1].shape[1]))\n",
    "\n",
    "        for k in range(len(centres)):\n",
    "            mean = centres[k]\n",
    "            v = np.random.randint(1, 4)\n",
    "            var = v * self.Grid_dim / len(centres)\n",
    "            pdf.append(multivariate_normal(mean, var))\n",
    "\n",
    "            pdf_tot += pdf[k].pdf(self.Grid)\n",
    "\n",
    "        # Normalize\n",
    "        pdf_tot += 0.0005\n",
    "        pdf_cum = pdf_tot / (sum(sum(pdf_tot)))\n",
    "\n",
    "        if c == \"O\":\n",
    "            self.Trip_Origin_PDF = pdf_cum\n",
    "        elif c == \"D\":\n",
    "            self.Trip_Destination_PDF = pdf_cum\n",
    "\n",
    "        if plt_opt:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "            if c == \"O\":\n",
    "                ax.plot_surface(self.Grid[:, :, 0], self.Grid[:, :, 1], pdf_cum, cmap='viridis',\n",
    "                                linewidth=0)\n",
    "                ax.set_xlabel('X axis')\n",
    "                ax.set_ylabel('Y axis')\n",
    "                ax.set_zlabel('Z axis')\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure()\n",
    "                plt.contourf(self.Grid[:, :, 0], self.Grid[:, :, 1], pdf_cum)\n",
    "                plt.title('Trip Origin Distribution')\n",
    "            elif c == \"D\":\n",
    "                ax.plot_surface(self.Grid[:, :, 0], self.Grid[:, :, 1], -1 * pdf_cum,\n",
    "                                cmap='viridis', linewidth=0)\n",
    "                ax.set_xlabel('X axis')\n",
    "                ax.set_ylabel('Y axis')\n",
    "                ax.set_zlabel('Z axis')\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure()\n",
    "                plt.contourf(self.Grid[:, :, 0], self.Grid[:, :, 1], pdf_cum)\n",
    "                plt.title('Trip Destination Distribution')\n",
    "\n",
    "    def draw_samples(self, PDF, nr_samples, plt_opt):\n",
    "\n",
    "        if len(PDF) != len(self.coordinates):\n",
    "            prob = np.reshape(PDF, (-1, 1))[:, 0]\n",
    "        else:\n",
    "            prob = PDF\n",
    "            PDF = np.reshape(prob, (int(np.sqrt(len(prob))), int(np.sqrt(len(prob)))))\n",
    "\n",
    "        sample_indices = np.random.choice(np.arange(len(prob)), nr_samples, p=prob)\n",
    "        samples = [self.coordinates[k] for k in sample_indices]\n",
    "        samples_x = [samples[k][0] for k in range(len(samples))]\n",
    "        samples_y = [samples[k][1] for k in range(len(samples))]\n",
    "\n",
    "        if plt_opt:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "            ax.plot_surface(self.Grid[:, :, 0], self.Grid[:, :, 1], PDF, cmap='viridis',\n",
    "                            linewidth=0)\n",
    "            ax.scatter(samples_x, samples_y)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.contourf(self.Grid[:, :, 0], self.Grid[:, :, 1], PDF)\n",
    "            plt.plot(samples_x, samples_y, 'o')\n",
    "\n",
    "        return samples, samples_x, samples_y\n",
    "\n",
    "    def generate_trips(self, samples, plt_opt):\n",
    "\n",
    "        Dest_PDF = copy.copy(self.Trip_Destination_PDF)\n",
    "        prob = np.reshape(Dest_PDF, (-1, 1))[:, 0]\n",
    "        Trips = []\n",
    "\n",
    "        for k in range(len(samples)):\n",
    "            ind = [distance.euclidean(samples[k], j) >= self.Lag * 20 for j in self.coordinates]\n",
    "            prob_temp = copy.copy(prob)\n",
    "            for index, item in enumerate(ind):\n",
    "                if item:\n",
    "                    prob_temp[index] = 0\n",
    "\n",
    "            pdf_cum = prob_temp / (sum(prob_temp))\n",
    "\n",
    "            D_samples, D_samples_x, D_samples_y = self.draw_samples(pdf_cum, 1, 0)\n",
    "\n",
    "            Trips.append((samples[k], D_samples[-1]))\n",
    "\n",
    "        if plt_opt:\n",
    "            plt.figure()\n",
    "            plt.contourf(self.Grid[:, :, 0], self.Grid[:, :, 1], Dest_PDF)\n",
    "            for k in range(len(Trips)):\n",
    "                x = Trips[k][0][0]\n",
    "                y = Trips[k][0][1]\n",
    "                dx = Trips[k][1][0] - x\n",
    "                dy = Trips[k][1][1] - y\n",
    "\n",
    "                plt.arrow(x, y, dx, dy, width=0.1, head_width=2)\n",
    "                plt.plot(x, y, 'o', c='black')\n",
    "        return Trips\n",
    "\n",
    "\n",
    "# Generic synthetic grid network\n",
    "class SyntheticNetwork:\n",
    "    def __init__(self, N, V, Cs, Cv, B, T, W, K, vehicle_speed):\n",
    "\n",
    "        self.nr_regions = N\n",
    "        self.grid_space = int(np.sqrt(N))\n",
    "        self.nr_vehicles = V\n",
    "\n",
    "        self.C_s = Cs\n",
    "        self.C_v = Cv\n",
    "\n",
    "        self.nr_bikes = B\n",
    "        self.time_horizon = T\n",
    "        self.time_window = W\n",
    "        self.nr_lag_steps = K\n",
    "\n",
    "        self.centres = None\n",
    "        self.adjacency_matrix = None\n",
    "        self.F = None\n",
    "\n",
    "        self.create_centres()\n",
    "        self.dist = self.distance_matrix()\n",
    "        self.create_adjacency_matrix(vehicle_speed)\n",
    "        self.ds_0 = self.create_initial_bike_distr()\n",
    "        self.dv_0 = self.create_initial_vehicle_load()\n",
    "        self.z_0 = self.create_initial_vehicle_distr()\n",
    "\n",
    "        self.create_demand()\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"\\n\"\n",
    "        s += f\"Network has {self.nr_regions} regions, {self.nr_vehicles} vehicles, and {self.nr_bikes} bikes.\\n\"\n",
    "        s += f\"Time horizon is {self.time_horizon} steps, and maximum lag is {self.nr_lag_steps} steps.\\n\"\n",
    "        s += f\"Regions hold {np.mean(self.C_s):.1f} bikes, and vehicles hold {np.mean(self.C_v):.1f} bikes on average.\"\n",
    "        return s\n",
    "\n",
    "    def print_stats(self):\n",
    "        print(\"Initial vehicle conditions:\")\n",
    "        N, V = self.nr_regions, self.nr_vehicles\n",
    "        for v in range(V):\n",
    "            z_temp = self.z_0[v:(N*V)+v:V, 0].reshape(N)\n",
    "            start_location = np.argwhere(z_temp)[0]\n",
    "            print(f\"  Vehicle #{v:2d} starts in region {start_location[0]:2d} with {self.dv_0[v]:2d}/{self.C_v[v]:2d} slots filled.\")\n",
    "        print(\"Initial bike numbers by region:\")\n",
    "        print(\" \", [int(x) for x in self.ds_0.squeeze()])\n",
    "        if np.sum(self.ds_0) != self.nr_bikes:\n",
    "            print(f\"Warning: {np.sum(self.ds_0)} (and not {self.nr_bikes}) bikes in network!\")\n",
    "\n",
    "    def create_centres(self):\n",
    "\n",
    "        self.centres = []\n",
    "        for k in range(self.grid_space):\n",
    "            for j in range(self.grid_space):\n",
    "                x = j * 100. / self.grid_space + 100. / (2 * self.grid_space)\n",
    "                y = k * 100. / self.grid_space + 100. / (2 * self.grid_space)\n",
    "                self.centres.append(np.array([x, y]))\n",
    "\n",
    "    def create_adjacency_matrix(self, max_travel_dist):\n",
    "        N = self.nr_regions\n",
    "        self.adjacency_matrix = np.zeros((N, N), dtype=int)\n",
    "        ind = np.where(self.dist <= max_travel_dist)\n",
    "        self.adjacency_matrix[ind] = 1\n",
    "\n",
    "    def create_initial_bike_distr(self):\n",
    "\n",
    "        N = self.nr_regions\n",
    "        B = float(self.nr_bikes)\n",
    "\n",
    "        r = np.random.randint(0, B / 2, size=(N, 1))\n",
    "        x_0 = np.round((r * B / sum(r)))\n",
    "        for k in range(N):\n",
    "            x_0[k] = min(x_0[k], self.C_s[k])\n",
    "\n",
    "        while int(sum(x_0)) > self.nr_bikes:\n",
    "            i = np.random.randint(0, N)\n",
    "            if x_0[i] > 0:\n",
    "                x_0[i] -= 1\n",
    "        while int(sum(x_0)) < self.nr_bikes:\n",
    "            i = np.random.randint(0, N)\n",
    "            if x_0[i] < self.C_s[i]:\n",
    "                x_0[i] += 1\n",
    "\n",
    "        return x_0\n",
    "\n",
    "    def create_initial_vehicle_distr(self):\n",
    "\n",
    "        N = self.nr_regions\n",
    "        V = self.nr_vehicles\n",
    "\n",
    "        z_0 = np.zeros([N * N * V, 1])\n",
    "\n",
    "        available_regions = np.arange(N)\n",
    "\n",
    "        initial_regions = []\n",
    "        for v in range(V):\n",
    "            r = np.random.randint(0, len(available_regions), size=1)\n",
    "            initial_regions.append(int(available_regions[r]))\n",
    "            ir = initial_regions[v]\n",
    "            z_0[ir * V + v] = 1\n",
    "\n",
    "        return z_0\n",
    "\n",
    "    def create_initial_vehicle_load(self):\n",
    "\n",
    "        return np.zeros((self.nr_vehicles, 1))\n",
    "\n",
    "    def modify_nr_vehicles(self, V, C_v):\n",
    "        self.nr_vehicles = V\n",
    "        self.C_v = C_v\n",
    "        self.z_0 = self.create_initial_vehicle_distr()\n",
    "        self.dv_0 = self.create_initial_vehicle_load()\n",
    "\n",
    "    def create_demand(self):\n",
    "\n",
    "        G = 100.\n",
    "        Nr_Origins = 3\n",
    "        Nr_Destinations = 5\n",
    "\n",
    "        Demand = SyntheticDemand(self.nr_lag_steps, Nr_Origins, Nr_Destinations, G)\n",
    "\n",
    "        F = [[np.zeros((self.nr_regions, self.nr_regions))\n",
    "              for _ in range(self.nr_lag_steps + 1)]\n",
    "             for _ in range(self.time_horizon + 1)]\n",
    "\n",
    "        total_demand = 0\n",
    "\n",
    "        for k in range(self.time_window):\n",
    "\n",
    "            Demand.create_origins()\n",
    "            Demand.create_destinations()\n",
    "\n",
    "            for t in range(self.time_horizon // self.time_window):\n",
    "                Demand.create_prob_distribution(\"O\", 0)\n",
    "                Demand.create_prob_distribution(\"D\", 0)\n",
    "\n",
    "                n = max(int(np.random.normal(0.15 * self.nr_bikes, 0.075 * self.nr_bikes)), 0)\n",
    "                origin_samples, ox, oy = Demand.draw_samples(Demand.Trip_Origin_PDF, n, 0)\n",
    "\n",
    "                Trips = Demand.generate_trips(origin_samples, 0)\n",
    "\n",
    "                for j in range(len(Trips)):\n",
    "                    Lag = int(distance.euclidean(Trips[j][0], Trips[j][1]) / 20)\n",
    "                    o = int(Trips[j][0][0] / (G / np.sqrt(self.nr_regions))) + int(\n",
    "                        np.sqrt(self.nr_regions) * int(\n",
    "                            Trips[j][0][1] / (G / np.sqrt(self.nr_regions))))\n",
    "                    d = int(Trips[j][1][0] / (G / np.sqrt(self.nr_regions))) + int(\n",
    "                        np.sqrt(self.nr_regions) * int(\n",
    "                            Trips[j][1][1] / (G / np.sqrt(self.nr_regions))))\n",
    "                    try:\n",
    "                        F[k * self.time_horizon // self.time_window + t + 1][Lag][o, d] += 1\n",
    "                    except Exception as e:\n",
    "                        print(\"Error\", e)\n",
    "\n",
    "                total_demand += len(Trips)\n",
    "                print(f\"  {len(Trips)} trips created at time {k * self.time_horizon // self.time_window + t + 1}.\")\n",
    "\n",
    "        print(f\"  Total demand is {total_demand} trips; {float(total_demand) / self.nr_bikes:.2f} trips/bike.\")\n",
    "\n",
    "        self.F = F\n",
    "\n",
    "    def distance_matrix(self):\n",
    "\n",
    "        dist_matrix = np.zeros((self.nr_regions, self.nr_regions))\n",
    "\n",
    "        for k in range(self.nr_regions):\n",
    "            for l in range(self.nr_regions):\n",
    "                dist_matrix[k, l] = (distance.euclidean(self.centres[k], self.centres[l]))\n",
    "\n",
    "        return dist_matrix\n",
    "\n",
    "    def repos_penalty(self, t, P):\n",
    "        dist = self.dist.copy()\n",
    "        np.fill_diagonal(dist, 0)\n",
    "\n",
    "        return P * dist\n",
    "\n",
    "    def trip_reward(self, t, k, R1):\n",
    "\n",
    "        dist = self.dist.copy()\n",
    "        np.fill_diagonal(dist, R1)\n",
    "\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2017-2019 ETH Zurich, Automatic Control Lab, Joe Warrington, Dominik Ruchti\n",
    "\n",
    "import gurobipy as gu\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "import matplotlib as mpl\n",
    "if os.environ.get('DISPLAY', '') == '' and platform.system() == 'Linux':\n",
    "    mpl.use('Agg')  # Use non-interactive Agg backend on Linux server\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "from scipy.io import savemat, loadmat\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "gu_status_codes = {1: \"Loaded\", 2: \"Optimal\", 3: \"Infeasible\", 4: \"Infeasible or unbounded\",\n",
    "                   5: \"Unbounded\", 6: \"Cutoff\", 7: \"Iteration limit\", 8: \"Node limit\",\n",
    "                   9: \"Time limit\", 10: \"Solution limit\", 11: \"Interrupted\", 12: \"Numerical issues\",\n",
    "                   13: \"Suboptimal\", 14: \"In progress\", 15: \"User objective limit\"}\n",
    "\n",
    "\n",
    "# Stochastic approximation model\n",
    "class SAModel(object):\n",
    "\n",
    "    def __init__(self, nw, cost_params, alg_params, t_horizon, instance, label=''):\n",
    "        self.T = t_horizon\n",
    "        self.nw = nw\n",
    "        self.cut_lists = []\n",
    "        self.w_vars_added = [0] * self.T\n",
    "        self.w_indices = []\n",
    "        self.alg_params = alg_params\n",
    "        self.cost_params = cost_params\n",
    "        self.instance_no = instance\n",
    "\n",
    "        # Optimization models\n",
    "        self.m_s1, self.c_list_s1, self.x_s1, self.vstage_s1 = self.create_s1_model(cost_params)\n",
    "        self.m_s1r = self.m_s1.relax()\n",
    "        self.m_s1_warmstart = None\n",
    "        self.set_s1_initial_state()\n",
    "\n",
    "        self.m_s2, self.c_list_s2, self.x_s2 = self.create_s2_model(cost_params)\n",
    "        self.m_s2r = self.m_s2.relax()\n",
    "        self.set_s2_constr_rhs()\n",
    "\n",
    "        # Store value function approximations (vfpp = VF pre-projection; vf = Value Function)\n",
    "        self.vfpp = [np.zeros((self.T, self.nw.nr_regions, 2 * self.alg_params['max_dev']))]\n",
    "        self.vf_proj_m, self.vf_proj_x = self.setup_unit_projection_model(concave=False,\n",
    "                                                                          max_slope=25.0)\n",
    "        self.vf = [self.project_vf(self.vfpp[0])]\n",
    "        self.last_x1_sol = None\n",
    "        # Dictionaries for cost estimates\n",
    "        self.lb, self.ub, self.stats = {}, {}, {}\n",
    "        self.ub_no_action, self.stats_no_action = None, None\n",
    "        # Results dataframe\n",
    "        self.results_df = pd.DataFrame(columns=['N', 'V', 'T', 'Inst.', 'k', 'Integer',\n",
    "                                                'Cost', 'SR', 't1', 't2'])\n",
    "        self.results_label = label\n",
    "\n",
    "    def approx(self):\n",
    "        \"\"\"\n",
    "        Computes an approximate solution to the stochastic DRRP by\n",
    "        (i) Iteratively approximating the second-stage value function, representing the expected\n",
    "            cost of unserved customers\n",
    "        (ii) Using the approximate second-stage value function to generate a solution to the first\n",
    "            stage\n",
    "        :return: Nothing, outputs file results to directory ./output/\n",
    "        \"\"\"\n",
    "        N, V, T, i = self.nw.nr_regions, self.nw.nr_vehicles, self.T, self.instance_no\n",
    "\n",
    "        random_s1, nominal_s2 = self.alg_params['random_s1'], self.alg_params['nominal_s2']\n",
    "        save_iter_models, max_dev = self.alg_params['save_iter_models'], self.alg_params['max_dev']\n",
    "        eval_cost_k = self.alg_params['eval_cost_k']\n",
    "\n",
    "        # (i) Iteratively approximate second-stage value function with a separable function\n",
    "\n",
    "        n_iter = self.alg_params['n_iter']\n",
    "        for k in range(1, n_iter + 1):\n",
    "            print(\"k = %d:\" % k)\n",
    "            if save_iter_models and not random_s1:\n",
    "                print(\"Saving model...\")\n",
    "                self.m_s1.write('output/model_N%d_V%d_T%d_i%d_k%d' % (N, V, T, i, k) +\n",
    "                                self.results_label + '.mps')\n",
    "\n",
    "            # 1. Optimize vehicle routes and repositioning actions against current VFA, return xk\n",
    "            if random_s1:\n",
    "                s1_cost, cost_to_go, ts1 = 0.0, 0.0, 0.0\n",
    "                s1_sol = np.random.random_integers(-max_dev, max_dev - 1, (N, T))\n",
    "                s1_really_solved = False\n",
    "            else:\n",
    "                s1_cost, cost_to_go, s1_sol, ts1 = self.optimize_stage(stage=1)\n",
    "                s1_really_solved = True\n",
    "            self.last_x1_sol = s1_sol\n",
    "            # self.print_s1_solution(s1_sol)\n",
    "            # 2. Update initial conditions of S2 model\n",
    "            self.set_s2_constr_rhs(s1_sol, really_solved_s1=s1_really_solved)\n",
    "            # 3. Evaluate lower and upper bounds\n",
    "            self.lb[k] = s1_cost\n",
    "            eval_this_iteration = k in eval_cost_k or (N == 64 and V == 9)\n",
    "            if eval_this_iteration:\n",
    "                self.ub[k], self.stats[k] = self.estimate_costs(s1_cost - cost_to_go,\n",
    "                                                                deterministic_s2=nominal_s2)\n",
    "            # 4. Optimize journeys given xk, and return objective function value and multipliers\n",
    "            self.resample_s2_demand(deterministic=nominal_s2)\n",
    "            s2_cost, s2_sol, s2_lambdas, ts2 = self.optimize_stage(stage=2)\n",
    "            # 5. Update value function using step size rule\n",
    "            self.update_vf(s1_sol, s2_lambdas, k, verify=False)\n",
    "            # 6. Log results for this iteration\n",
    "            if eval_this_iteration:\n",
    "                df_entry = {'N': np.rint(N), 'V': np.rint(V), 'T': np.rint(T), 'Inst.': np.rint(i),\n",
    "                            'k': np.rint(k), 'Integer': 0,\n",
    "                            'Cost': np.round(self.ub[k]['cost'], 6),\n",
    "                            'SR': np.round(self.stats[k]['sr'] * 100, 6),\n",
    "                            't1': np.round(ts1, 6), 't2': np.round(ts2, 6)}\n",
    "            else:\n",
    "                df_entry = {'N': np.rint(N), 'V': np.rint(V), 'T': np.rint(T), 'Inst.': np.rint(i),\n",
    "                            'k': np.rint(k), 'Integer': 0,\n",
    "                            't1': np.round(ts1, 6), 't2': np.round(ts2, 6)}\n",
    "            self.results_df = self.results_df.append(df_entry, ignore_index=True)\n",
    "            if not self.alg_params['random_s1'] or (self.alg_params['random_s1'] and\n",
    "                                                    divmod(k, 10)[1] == 0):\n",
    "                self.results_df.to_csv('output/stats_N%d_V%d_T%d_i%d' % (N, V, T, i) +\n",
    "                                       self.results_label + '.csv', index=False)\n",
    "\n",
    "        # Save final approximate VF for use in subsequent optimizations\n",
    "        mat_fname = 'vfs/N%d_V%d_T%d_i%d_k%d' % (N, V, T, i, n_iter) + self.results_label + '.mat'\n",
    "        savemat(mat_fname, {'vf': self.vf[-1]})\n",
    "\n",
    "        # (ii) Generate a final first-stage solution and estimate resulting second-stage costs\n",
    "        if self.alg_params['final_sol']:\n",
    "            final_method = self.alg_params['final_sol_method']\n",
    "            final_ts1, final_ub, final_stats = self.integer_solve(method=final_method)\n",
    "            df_entry = {'N': np.rint(N), 'V': np.rint(V), 'T': np.rint(T), 'Inst.': np.rint(i),\n",
    "                        'k': n_iter+1, 'Integer': final_method, 't1': np.round(final_ts1, 6),\n",
    "                        'Cost': np.round(final_ub['cost'], 6),\n",
    "                        'SR': np.round(final_stats['sr'] * 100, 6)}\n",
    "            self.results_df = self.results_df.append(df_entry, ignore_index=True)\n",
    "            self.results_df['N'] = self.results_df['N'].map(lambda x: \"%d\" % x)\n",
    "            self.results_df['V'] = self.results_df['V'].map(lambda x: \"%d\" % x)\n",
    "            self.results_df['T'] = self.results_df['T'].map(lambda x: \"%d\" % x)\n",
    "            self.results_df['Inst.'] = self.results_df['Inst.'].map(lambda x: \"%d\" % x)\n",
    "            self.results_df['k'] = self.results_df['k'].map(lambda x: \"%d\" % x)\n",
    "            self.results_df.to_csv('output/stats_N%d_V%d_T%d_i%d' % (N, V, T, i) +\n",
    "                                   self.results_label + '.csv', index=False)\n",
    "\n",
    "    def optimize_stage(self, stage=1, mute=False):\n",
    "        m = self.m_s1 if stage == 1 else self.m_s2\n",
    "        x_list = self.x_s1 if stage == 1 else self.x_s2\n",
    "        # if stage == 1 and self.m_s1_warmstart is not None:\n",
    "        #     for i, v in enumerate(x_list):\n",
    "        #         v.setAttr('VarHintVal', self.m_s1_warmstart[i])\n",
    "        m.optimize()\n",
    "        if m.status in [2, 9, 13]:\n",
    "            # print(\"  Solved S%d in %.3f s, status %d.\" % (stage, m.runtime, m.status)\n",
    "            cost = m.getObjective().getValue()\n",
    "            opt_vec = [v.x for v in x_list]\n",
    "            if not mute:\n",
    "                print(\"  S%d solved in %.3f s.\" % (stage, m.runtime))\n",
    "            if stage == 1:\n",
    "                # self.m_s1_warmstart = opt_vec\n",
    "                cost_to_go = np.sum([1.0 * v.x for v in x_list\n",
    "                                     if v.getAttr(\"VarName\")[:4] == \"epi_\"])\n",
    "                return cost, cost_to_go, opt_vec, m.runtime\n",
    "            else:\n",
    "                lambdas = [c.Pi for c in self.c_list_s2[0]]  # Station dynamics multipliers\n",
    "                if not mute:\n",
    "                    print(\"  lambda stats: # non-zero: %d/%d. Max: %.3f. Mean: %.3f\" % \\\n",
    "                        (np.count_nonzero(lambdas), len(lambdas), np.max(lambdas), np.mean(lambdas)))\n",
    "                pen_created_bikes = self.cost_params['created bike cost'] * \\\n",
    "                                    np.sum([v.x for v in x_list if v.varname[:4] == 'crea'])\n",
    "                pen_lost_bikes = self.cost_params['lost bike cost'] * \\\n",
    "                                 np.sum([v.x for v in x_list if v.varname[:4] == 'lost'])\n",
    "                return cost - pen_created_bikes - pen_lost_bikes, opt_vec, lambdas, m.runtime\n",
    "        elif m.status in [3, 4]:\n",
    "            print(\"Optimization status for S%d: %d (%s)!\" % (stage, m.status,\n",
    "                                                             gu_status_codes[m.status]))\n",
    "            m.computeIIS()\n",
    "            print(\"Constraints forming Irreducible Inconsistent Subsystem:\")\n",
    "            for c in m.getConstrs():\n",
    "                if c.getAttr('IISConstr') != 0:\n",
    "                    print (c.ConstrName)\n",
    "                    self.print_non_zero_coeffs([c], m)\n",
    "            for v in m.getVars():\n",
    "                if v.iislb != 0:\n",
    "                    print (v.varname + \" LB of \" + str(v.lb))\n",
    "                if v.iisub != 0:\n",
    "                    print (v.varname + \" UB of \" + str(v.ub))\n",
    "        else:\n",
    "            print(\"Optimization status for S%d: %d (%s)! Exiting.\" % (stage, m.status,\n",
    "                                                                      gu_status_codes[m.status]))\n",
    "        raise SystemExit\n",
    "\n",
    "    def integer_only(self):\n",
    "        N, V, T, i = self.nw.nr_regions, self.nw.nr_vehicles, self.T, self.instance_no\n",
    "        n_iter = self.alg_params['n_iter']\n",
    "        self.results_df = pd.read_csv('output/stats_N%d_V%d_T%d_i%d' % (N, V, T, i) +\n",
    "                                      self.results_label + '.csv')\n",
    "        sol_method = self.alg_params['final_sol_method']\n",
    "        final_ts1, final_ub, final_stats = self.integer_solve(method=sol_method, load_vf=True)\n",
    "        df_entry = {'N': np.rint(N), 'V': np.rint(V), 'T': np.rint(T), 'Inst.': np.rint(i),\n",
    "                    'k': n_iter+1, 'Integer': sol_method, 't1': np.round(final_ts1, 6),\n",
    "                    'Cost': np.round(final_ub['cost'], 6),\n",
    "                    'SR': np.round(final_stats['sr'] * 100, 6)}\n",
    "        self.results_df = self.results_df.append(df_entry, ignore_index=True)\n",
    "        self.results_df['N'] = self.results_df['N'].map(lambda x: \"%d\" % x)\n",
    "        self.results_df['V'] = self.results_df['V'].map(lambda x: \"%d\" % x)\n",
    "        self.results_df['T'] = self.results_df['T'].map(lambda x: \"%d\" % x)\n",
    "        self.results_df['Inst.'] = self.results_df['Inst.'].map(lambda x: \"%d\" % x)\n",
    "        self.results_df['k'] = self.results_df['k'].map(lambda x: \"%d\" % x)\n",
    "        self.results_df.to_csv('output/stats_N%d_V%d_T%d_i%d' % (N, V, T, i) +\n",
    "                               self.results_label + '.csv')\n",
    "\n",
    "    def integer_solve(self, method=None, load_vf=False):\n",
    "        \"\"\"\n",
    "        Generate a final integer solution using the value function approximation derived so far.\n",
    "        \"\"\"\n",
    "        print(\"Generating final S1 solution using '\" + method + \"' method...\")\n",
    "        if load_vf:\n",
    "            N, V, T, i = self.nw.nr_regions, self.nw.nr_vehicles, self.T, self.instance_no\n",
    "            n_it = self.alg_params['n_iter']\n",
    "            mat_fname = 'vfs/N%d_V%d_T%d_i%d_k%d' % (N, V, T, i, n_it) + self.results_label + '.mat'\n",
    "            self.load_s1_cost_to_go(mat_fname)\n",
    "        if method == 'greedy_seq':\n",
    "            # Compute RV actions one by one rather than sequentially, to reduce computational cost\n",
    "\n",
    "            # 1. Get RV list and initial locations from nw object\n",
    "            # For each RV in the list:\n",
    "            #     2. Fix model RH sides to allow optimization only over this RV\n",
    "            #     3. Optimize\n",
    "            #     4. Modify constraint RH sides to reflect redeployment actions and route chosen\n",
    "            #     5. Unfix as appropriate to allow next RV decisions to be made.\n",
    "            # 6. Recover final actions z,y and associated cost.\n",
    "\n",
    "            print(\"Method 'greedy_seq' not yet implemented. Exiting.\")\n",
    "            raise SystemExit()\n",
    "        elif method == 'random':\n",
    "            print(\"Method 'random' not yet implemented. Exiting.\")\n",
    "            raise SystemExit()\n",
    "        elif method == 'exact':\n",
    "            # Jointly optimize all actions exactly\n",
    "            self.unrelax_s1()\n",
    "            s1_cost, cost_to_go, s1_sol, ts1 = self.optimize_stage(stage=1)\n",
    "            print(\"  Exact S1 cost: %.3f\" % (s1_cost - cost_to_go))\n",
    "            # self.unrelax_s1(relax_or_unrelax='relax')  # 'Re-relax' model\n",
    "        else:\n",
    "            print(\"Unrecognised method for final S1 solution: \" + method + \". Exiting.\")\n",
    "            raise SystemExit()\n",
    "        self.set_s2_constr_rhs(s1_sol, really_solved_s1=True)\n",
    "        ub, stats = self.estimate_costs(s1_cost - cost_to_go, deterministic_s2=False)\n",
    "        return ts1, ub, stats\n",
    "\n",
    "    def update_vf(self, s1_sol_in, lambdas_in, k, verify=False):\n",
    "        # Generate gradient from lambdas and S1 solution\n",
    "        vf_old = self.vf[-1]\n",
    "        xi_k = self.generate_xi(vf_old, s1_sol_in, lambdas_in)\n",
    "        # Generate new VF based on step size rule\n",
    "        alpha = self.step_size(k)\n",
    "        vf_new = vf_old + alpha * xi_k\n",
    "        self.vfpp.append(vf_new)\n",
    "        # Project new VF onto feasible set (convex functions) and append to list.\n",
    "        vf_new_p = self.project_vf(vf_new)\n",
    "        self.vf.append(vf_new_p)\n",
    "        # Update S1 model to reflect new VF\n",
    "        vf_constrs = self.c_list_s1[5]\n",
    "        max_dev = self.alg_params['max_dev']\n",
    "        T, N, ni = self.T, self.nw.nr_regions, 2 * self.alg_params['max_dev']\n",
    "        for it, n, l in itertools.product(range(T), range(N), range(ni)):\n",
    "            t = it + 1\n",
    "            ev_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * N + n  # Epigraph variable\n",
    "            yp_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * n  # Unload bikes variable\n",
    "            ym_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * n + 1  # Load bikes var\n",
    "            # assert self.x_s1[ev_index].getAttr(\"VarName\") == 'epi_%d_%d' % (n, t)\n",
    "            vf_constr_index = it * N * ni + n * ni + l  # Index of epigraph constraint\n",
    "            # assert vf_constrs[vf_constr_index].getAttr(\"ConstrName\") == 'vf_%d_%d_%d' % \\\n",
    "            #     (t, n, l - self.alg_params['max_dev'])\n",
    "            self.m_s1.chgCoeff(vf_constrs[vf_constr_index], self.x_s1[ym_index], vf_new_p[it, n, l])\n",
    "            self.m_s1.chgCoeff(vf_constrs[vf_constr_index], self.x_s1[yp_index], -vf_new_p[it, n, l])\n",
    "            vf_constrs[vf_constr_index].setAttr(\"RHS\", -1 * (np.sum(vf_new_p[it, n, :l])\n",
    "                                                             + (max_dev - l) * vf_new_p[it, n, l]))\n",
    "        self.m_s1.update()\n",
    "        if verify and divmod(k, 1)[1] == 0:\n",
    "            n, t = 3, 1\n",
    "            it = t - 1\n",
    "            ev_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * N + n  # Epigraph variable\n",
    "            yp_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * n  # Unload bikes variable\n",
    "            ym_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * n + 1  # Load bikes var\n",
    "            m, c = [], []  # List for storing lines in the form y >= mx + c\n",
    "            assert self.x_s1[yp_index].getAttr(\"VarName\") == 'y_%d_%d+' % (n, t)\n",
    "            assert self.x_s1[ym_index].getAttr(\"VarName\") == 'y_%d_%d-' % (n, t)\n",
    "            for l in range(ni):\n",
    "                vf_constr_index = it * N * ni + n * ni + l\n",
    "                assert vf_constrs[vf_constr_index].getAttr(\"ConstrName\") == 'vf_%d_%d_%d' % \\\n",
    "                    (it + 1, n, l - max_dev)\n",
    "                assert self.m_s1.getCoeff(vf_constrs[vf_constr_index], self.x_s1[ev_index]) == -1.\n",
    "                # self.print_non_zero_coeffs([vf_constrs[vf_constr_index]], self.m_s1)\n",
    "                m.append(self.m_s1.getCoeff(vf_constrs[vf_constr_index], self.x_s1[ym_index]))\n",
    "                c.append(-1 * vf_constrs[vf_constr_index].getAttr(\"RHS\"))\n",
    "\n",
    "            plot_range = range(-max_dev, max_dev + 1)\n",
    "            plt.figure()\n",
    "            plt.subplot(211)\n",
    "            vf_stored = self.vf[-1][it, n, :]\n",
    "            nx, vc = len(vf_stored), np.cumsum(vf_stored)\n",
    "            plt.plot(plot_range, np.hstack((np.array([-vc[max_dev]]), vc - vc[max_dev])), 'b')\n",
    "            plt.ylim([-2, 10])\n",
    "            plt.subplot(212)\n",
    "            for l in range(ni):\n",
    "                plt.plot(plot_range, [m[l] * x + c[l] - c[max_dev] for x in plot_range])\n",
    "            plt.ylim([-2, 10])\n",
    "            plt.show()\n",
    "\n",
    "    def load_s1_cost_to_go(self, fname):\n",
    "        \"\"\"\n",
    "        Load cost-to-go data from file fname and update model epigraph variables for the cost-to-go\n",
    "        to reflect this.\n",
    "        :param fname: .mat file including relative location. Loads as dict, with key ['vf']\n",
    "        :return: Nothing; updates S1 model in place.\n",
    "        \"\"\"\n",
    "        vf_new_p = loadmat(fname)['vf']\n",
    "        vf_constrs = self.c_list_s1[5]\n",
    "        max_dev = self.alg_params['max_dev']\n",
    "        T, N, ni = self.T, self.nw.nr_regions, 2 * self.alg_params['max_dev']\n",
    "        for it, n, l in itertools.product(range(T), range(N), range(ni)):\n",
    "            t = it + 1\n",
    "            ev_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * N + n  # Epigraph variable\n",
    "            yp_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * n  # Unload bikes variable\n",
    "            ym_index = it * self.vstage_s1 + N + (N * N) + (N * N) + 2 * n + 1  # Load bikes var\n",
    "            assert self.x_s1[ev_index].getAttr(\"VarName\") == 'epi_%d_%d' % (n, t)\n",
    "            vf_constr_index = it * N * ni + n * ni + l  # Index of epigraph constraint\n",
    "            assert vf_constrs[vf_constr_index].getAttr(\"ConstrName\") == 'vf_%d_%d_%d' % \\\n",
    "                (t, n, l - self.alg_params['max_dev'])\n",
    "            self.m_s1.chgCoeff(vf_constrs[vf_constr_index], self.x_s1[ym_index], vf_new_p[it, n, l])\n",
    "            self.m_s1.chgCoeff(vf_constrs[vf_constr_index], self.x_s1[yp_index],\n",
    "                               -vf_new_p[it, n, l])\n",
    "            vf_constrs[vf_constr_index].setAttr(\"RHS\", -1 * (np.sum(vf_new_p[it, n, :l])\n",
    "                                                             + (max_dev - l) * vf_new_p[it, n, l]))\n",
    "        self.m_s1.update()\n",
    "\n",
    "    def create_s1_model(self, cost_params, print_stats=True):\n",
    "        N, V, K, T = self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps, self.T\n",
    "        C_s, C_v = self.nw.C_s, self.nw.C_v\n",
    "        assert C_v.tolist().count(C_v[0]) == len(C_v)  # All vehicles have the same capacity\n",
    "        vmc = cost_params['vehicle movt cost']\n",
    "        ypluscost, yminuscost = cost_params['load cost'], cost_params['unload cost']\n",
    "\n",
    "        ds_0, max_dev = self.nw.ds_0, self.alg_params['max_dev']\n",
    "\n",
    "        m = gu.Model(\"DRRP central flow\")\n",
    "        m.params.outputflag = 0 if N < 100 else 1\n",
    "        m.params.mipgap = 5e-3\n",
    "        m.params.threads = 2\n",
    "        m.params.optimalitytol = 1e-3\n",
    "        # m.params.mipgapabs = 5e-4\n",
    "        m.params.timelimit = 1200\n",
    "        m.params.method = 2\n",
    "        m.params.crossover = 0\n",
    "        x, vars_per_stage = [], 0\n",
    "\n",
    "        t1 = time.time()\n",
    "        # Define constraints in one-stage problem\n",
    "        st_dyns = []  # Station fill level dynamics\n",
    "        for t in range(1, T + 1):\n",
    "            for n in range(N):\n",
    "                st_dyns.append(m.addConstr(name='st_dyn_%d_%d' % (t, n),\n",
    "                                           lhs=0, rhs=0, sense=gu.GRB.EQUAL))\n",
    "\n",
    "        flow_dyns = []  # Bike-on-vehicle flow conservation\n",
    "        b_flow_caps = []  # Bike-on-vehicle flow limits\n",
    "        for t in range(1, T + 1):\n",
    "            for i in range(N):\n",
    "                flow_dyns.append(m.addConstr(name='flow_dyns_%d_%d' % (t, i),\n",
    "                                             lhs=0, rhs=0, sense=gu.GRB.EQUAL))\n",
    "                for j in range(N):\n",
    "                    b_flow_caps.append(m.addConstr(name='flow_cap_%d_%d_%d' % (t, i, j),\n",
    "                                                   lhs=0, rhs=0, sense=gu.GRB.LESS_EQUAL))\n",
    "\n",
    "        z_dyns = []  # Truck movement consistency constraints\n",
    "        # vehicle_flow_lbs = []  # Vehicle consistency (redundant)\n",
    "        for t in range(1, T + 1):\n",
    "            for n in range(N):\n",
    "                z_dyns.append(m.addConstr(name='z_dyn_%d_%d' % (t, n), lhs=0, rhs=0,\n",
    "                                          sense=gu.GRB.EQUAL))\n",
    "            # vehicle_flow_lbs.append(m.addConstr(name='vfl_%d' % t, lhs=0, rhs=V,\n",
    "            #                                     sense=gu.GRB.EQUAL))\n",
    "        # Index of time t+1, station n: (tN + n)\n",
    "\n",
    "        # Epigraph constraints for value function for load/unload sum for time t and station n\n",
    "        vfs, lb, ub = [], -self.alg_params['max_dev'], self.alg_params['max_dev']\n",
    "        for t in range(1, T + 1):\n",
    "            for n in range(N):\n",
    "                for l in range(lb, ub):\n",
    "                    vfs.append(m.addConstr(name='vf_%d_%d_%d' % (t, n, l), lhs=0, rhs=0,\n",
    "                                           sense=gu.GRB.LESS_EQUAL))\n",
    "        n_vf = ub - lb  # Number of segments in each station's second stage VF\n",
    "\n",
    "        m.update()\n",
    "\n",
    "        if self.alg_params['relax_s1'] == \"All z\":\n",
    "            t_relax_dict = {t: gu.GRB.CONTINUOUS for t in range(1, T + 1)}\n",
    "        elif self.alg_params['relax_s1'] == \"No z\":\n",
    "            t_relax_dict = {t: gu.GRB.INTEGER for t in range(1, T + 1)}\n",
    "        elif not isinstance(self.alg_params['relax_s1'], bool) and \\\n",
    "                isinstance(self.alg_params['relax_s1'], int) and \\\n",
    "                self.alg_params['relax_s1'] <= T:\n",
    "            t_relax_dict = {t: gu.GRB.INTEGER if t <= self.alg_params['relax_s1']\n",
    "                            else gu.GRB.CONTINUOUS\n",
    "                            for t in range(1, T + 1)}\n",
    "        else:\n",
    "            print(\"Cannot use self.alg_params['relax_s1'] value \" + repr(self.alg_params['relax_s1']))\n",
    "            print(\"Legal values: 'All z', 'No z', or integer 0 to T (indicating last integer step).\")\n",
    "            raise SystemExit()\n",
    "\n",
    "        # Create variables, and add their coefficients to the constraints defined above\n",
    "        for t in range(1, T + 1):\n",
    "            it = t - 1\n",
    "            for n in range(N):  # Station fill levels d_s\n",
    "                x.append(m.addVar(name=\"ds_%d_%d\" % (n, t),\n",
    "                                  vtype=gu.GRB.CONTINUOUS,\n",
    "                                  lb=ds_0[n] - t * max_dev, ub=ds_0[n] + t * max_dev, obj=0.))\n",
    "                vars_per_stage += 1 if it == 0 else 0\n",
    "                m.chgCoeff(st_dyns[it * N + n], x[-1], 1)\n",
    "                if t < T:\n",
    "                    m.chgCoeff(st_dyns[(it + 1) * N + n], x[-1], -1)\n",
    "\n",
    "            for i in range(N):  # Bike flows on path from i to j\n",
    "                for j in range(N):\n",
    "                    x.append(m.addVar(name=\"dv_%d_%d_%d\" % (i, j, t),\n",
    "                                      vtype=gu.GRB.CONTINUOUS, lb=0, ub=np.sum(C_v), obj=0.))\n",
    "                    vars_per_stage += 1 if it == 0 else 0\n",
    "                    m.chgCoeff(flow_dyns[it * N + i], x[-1], 1)\n",
    "                    m.chgCoeff(b_flow_caps[it * N * N + i * N + j], x[-1], 1)\n",
    "                    if t < T:\n",
    "                        m.chgCoeff(flow_dyns[(it + 1) * N + j], x[-1], -1)\n",
    "\n",
    "            for i in range(N):  # Vehicle movements z\n",
    "                for j in range(N):\n",
    "                    z_obj_coeff = 0 if i == j else vmc\n",
    "                    zlb = 0 if (t > 3 and i == j == 0) else 0\n",
    "                    x.append(m.addVar(name=\"z_%d_%d_%d\" % (i, j, t),\n",
    "                                      vtype=t_relax_dict[t],\n",
    "                                      obj=z_obj_coeff,\n",
    "                                      lb=zlb, ub=self.nw.adjacency_matrix[i, j] * V))\n",
    "                    # x[-1].setAttr('BranchPriority', T - it)  # Branch on earlier time steps first\n",
    "                    vars_per_stage += 1 if it == 0 else 0\n",
    "                    m.chgCoeff(z_dyns[it * N + i], x[-1], 1)\n",
    "                    m.chgCoeff(b_flow_caps[it * N * N + i * N + j], x[-1], -C_v[0])\n",
    "                    # m.chgCoeff(vehicle_flow_lbs[it], x[-1], 1)\n",
    "                    if t < T:\n",
    "                        m.chgCoeff(z_dyns[(it + 1) * N + j], x[-1], -1)\n",
    "\n",
    "            for n in range(N):  # Load/unload actions y+/y-\n",
    "                yplb = 0 if (n == 2 and t == 2) else 0\n",
    "                x.append(m.addVar(name=\"y_%d_%d+\" % (n, t),\n",
    "                                  vtype=t_relax_dict[t],\n",
    "                                  lb=yplb, ub=np.sum(C_v), obj=ypluscost))\n",
    "                vars_per_stage += 1 if it == 0 else 0\n",
    "                m.chgCoeff(st_dyns[it * N + n], x[-1], 1)  # Load from station...\n",
    "                m.chgCoeff(flow_dyns[it * N + n], x[-1], -1)  # ... on to vehicle\n",
    "                ymub = np.sum(C_v) if (n == 2 and t == 2) else np.sum(C_v)\n",
    "                x.append(m.addVar(name=\"y_%d_%d-\" % (n, t),\n",
    "                                  vtype=t_relax_dict[t],\n",
    "                                  lb=0, ub=ymub, obj=yminuscost))\n",
    "                vars_per_stage += 1 if it == 0 else 0\n",
    "                m.chgCoeff(st_dyns[it * N + n], x[-1], -1)  # Unload onto station...\n",
    "                m.chgCoeff(flow_dyns[it * N + n], x[-1], 1)  # ... from vehicle\n",
    "\n",
    "            for n in range(N):  # Epigraph variables for value of new configuration\n",
    "                x.append(m.addVar(name='epi_%d_%d' % (n, t), vtype=gu.GRB.CONTINUOUS,\n",
    "                                  lb=-gu.GRB.INFINITY, ub=gu.GRB.INFINITY, obj=1.))\n",
    "                vars_per_stage += 1 if it == 0 else 0\n",
    "                for l in range(n_vf):\n",
    "                    m.chgCoeff(vfs[it * (N * n_vf) + n * n_vf + l], x[-1], -1)\n",
    "                    # Constraint form: v - epi <= 0\n",
    "\n",
    "        m.update()\n",
    "        t2 = time.time()\n",
    "        print(\"Stage 1 model created in %.3f s.\" % (t2 - t1))\n",
    "        if self.alg_params['relax_s1'] == 'All z':\n",
    "            print(\"  Using linear relaxation of S1 model.\")\n",
    "        elif self.alg_params['relax_s1'] == 'No z':\n",
    "            print(\"  Using full integer model for S1.\")\n",
    "        elif isinstance(self.alg_params['relax_s1'], int):\n",
    "            print(\"  Relaxing S1 z variables after t = %d.\" % self.alg_params['relax_s1'])\n",
    "\n",
    "        if print_stats:\n",
    "            n_continuous = len([v for v in m.getVars() if v.vtype == gu.GRB.CONTINUOUS])\n",
    "            n_binary = len([v for v in m.getVars() if v.vtype == gu.GRB.BINARY])\n",
    "            n_integer = len([v for v in m.getVars() if v.vtype == gu.GRB.INTEGER])\n",
    "            n_constraints = len(m.getConstrs())\n",
    "            print(\"  %d vars (%d cont, %d binary, %d int), %d constraints.\" % \\\n",
    "                  (len(x), n_continuous, n_binary, n_integer, n_constraints))\n",
    "\n",
    "        return m, [st_dyns, b_flow_caps, z_dyns, flow_dyns, None, vfs], x, vars_per_stage\n",
    "\n",
    "    def create_s2_model(self, cost_params, print_stats=True):\n",
    "        N, V, K, T = self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps, self.T\n",
    "        C_s, C_v = self.nw.C_s, self.nw.C_v  # Station and vehicle capacities\n",
    "        assert C_v.tolist().count(C_v[0]) == len(C_v)  # All vehicles have the same capacity\n",
    "        ldc, vmc = cost_params['lost demand cost'], cost_params['vehicle movt cost']\n",
    "        lost_bike_cost = cost_params['created bike cost']\n",
    "        created_bike_cost = cost_params['created bike cost']\n",
    "        ldc_spread_low = cost_params['lost demand cost spread low']\n",
    "        ldc_spread_high = cost_params['lost demand cost spread high']\n",
    "\n",
    "        m = gu.Model(\"Customer flow\")\n",
    "        m.params.outputflag = 0\n",
    "        m.params.optimalitytol = 1e-3\n",
    "        x = []\n",
    "\n",
    "        t1 = time.time()\n",
    "        # Define constraints in one-stage problem\n",
    "        st_dyns = []  # Station fill level dynamics\n",
    "        for t in range(1, T + 1):\n",
    "            for n in range(N):\n",
    "                st_dyns.append(m.addConstr(name='st_dyn_%d_%d' % (t, n),\n",
    "                                           lhs=0, rhs=0, sense=gu.GRB.EQUAL))\n",
    "\n",
    "        wd_constrs = []  # Constraints that limit customer movements to available capacity\n",
    "        for t in range(1, T + 1):\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    for k in range(K + 1):\n",
    "                        wd_constrs.append(m.addConstr(name='wd_%d_%d_%d_%d' % (t, i, j, k),\n",
    "                                                      lhs=0, rhs=0, sense=gu.GRB.LESS_EQUAL))\n",
    "        # Index of time t+1, origin i, destination j, lag k: (tN^2(K+1) + iN(K+1) + j(K + 1) + k)\n",
    "\n",
    "        q_constrs = []  # Constraints that propagate queues of customers due to arrive at stations\n",
    "        for t in range(1, T + 1):\n",
    "            for n in range(N):\n",
    "                for k in range(K):\n",
    "                    q_constrs.append(m.addConstr(name='q_constr_%d_%d_%d' % (t, n, k + 1),\n",
    "                                                 lhs=0, rhs=0, sense=gu.GRB.EQUAL))\n",
    "        # Index of time t+1, station n, lag k: (tNK + nK + (k-1))\n",
    "\n",
    "        zx_constrs = []  # Constraints that constrain previous state to be equal to its duplicate\n",
    "        nzx = N + (N * K)\n",
    "        for t in range(1, T + 1):\n",
    "            for c in range(nzx):\n",
    "                zx_constrs.append(m.addConstr(name='zx_constr_%d_%d' % (t, c), lhs=0, rhs=0,\n",
    "                                              sense=gu.GRB.EQUAL))\n",
    "\n",
    "        m.update()\n",
    "        all_demand_lost_cost = 0.  # Keep a running total of cost if all demand were unsatisfied\n",
    "\n",
    "        # Create variables, and add their coefficients to the constraints defined above\n",
    "        idx = 0\n",
    "        for t in range(1, T + 1):\n",
    "            it = t - 1\n",
    "            for n in range(N):  # Station fill levels d_s\n",
    "                x.append(m.addVar(name=\"ds_%d_%d\" % (n, t),\n",
    "                                  vtype=gu.GRB.CONTINUOUS, lb=0, ub=C_s[n], obj=0.))\n",
    "                m.chgCoeff(st_dyns[it * N + n], x[-1], 1)\n",
    "                if t < T:\n",
    "                    m.chgCoeff(zx_constrs[(it + 1) * nzx + n], x[-1], -1)\n",
    "                idx += 1\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    for k in [0]:  # Customer actions w\n",
    "                        dem = int(self.nw.F[t][k][i, j])\n",
    "                        for d in range(dem):\n",
    "                            value = np.random.uniform(low=ldc_spread_low * ldc,\n",
    "                                                      high=ldc_spread_high * ldc)  # Trip value\n",
    "                            x.append(m.addVar(name=\"w_%d_%d_%d_%d_%d\" % (i, j, k, t, d),\n",
    "                                              vtype=gu.GRB.CONTINUOUS, lb=0, ub=1, obj=-value))\n",
    "                            all_demand_lost_cost += value  # Since coefficients are -ve\n",
    "                            if i != j:\n",
    "                                m.chgCoeff(st_dyns[it * N + i], x[-1], 1)\n",
    "                                m.chgCoeff(st_dyns[it * N + j], x[-1], -1)\n",
    "                            m.chgCoeff(wd_constrs[it * (N * N * (K + 1)) +\n",
    "                                                  i * (N * (K + 1)) +\n",
    "                                                  j * (K + 1) +\n",
    "                                                  k], x[-1], 1)\n",
    "                            self.w_indices.append(idx)\n",
    "                            idx += 1\n",
    "                        self.w_vars_added[it] += dem\n",
    "                    for k in range(1, K + 1):  # Customer actions w\n",
    "                        dem = int(self.nw.F[t][k][i, j])\n",
    "                        for d in range(dem):\n",
    "                            value = np.random.uniform(low=ldc_spread_low * ldc,\n",
    "                                                      high=ldc_spread_high * ldc)  # Trip value\n",
    "                            x.append(m.addVar(name=\"w_%d_%d_%d_%d_%d\" % (i, j, k, t, d),\n",
    "                                              vtype=gu.GRB.CONTINUOUS, lb=0, ub=1, obj=-value))\n",
    "                            all_demand_lost_cost += value\n",
    "                            m.chgCoeff(st_dyns[it * N + i], x[-1], 1)\n",
    "                            m.chgCoeff(wd_constrs[it * (N * N * (K + 1)) +\n",
    "                                                  i * (N * (K + 1)) + j * (K + 1) + k], x[-1], 1)\n",
    "                            m.chgCoeff(q_constrs[it * N * K + j * K + (k - 1)], x[-1], -1)\n",
    "                            self.w_indices.append(idx)\n",
    "                            idx += 1\n",
    "                        self.w_vars_added[it] += dem\n",
    "\n",
    "            for n in range(N):  # Queues of customers due to arrive at stations, q\n",
    "                for k in range(1, K + 1):\n",
    "                    x.append(m.addVar(name='q_%d_%d_%d' % (n, k, t), vtype=gu.GRB.CONTINUOUS, lb=0,\n",
    "                                      ub=self.nw.nr_bikes, obj=0.))\n",
    "                    m.chgCoeff(q_constrs[it * N * K + n * K + (k - 1)], x[-1], 1)\n",
    "                    if t < T:\n",
    "                        m.chgCoeff(zx_constrs[(it + 1) * nzx + N + n * K + (k - 1)], x[-1], -1)\n",
    "                    idx += 1\n",
    "\n",
    "            for n in range(N):\n",
    "                x.append(m.addVar(name='lost_bike_%d_%d' % (n, t),\n",
    "                                  vtype=gu.GRB.CONTINUOUS, obj=lost_bike_cost, lb=0.))\n",
    "                m.chgCoeff(st_dyns[it * N + n], x[-1], 1)\n",
    "                idx += 1\n",
    "            for n in range(N):\n",
    "                x.append(m.addVar(name='created_bike_%d_%d' % (n, t),\n",
    "                                  vtype=gu.GRB.CONTINUOUS, obj=created_bike_cost, lb=0.))\n",
    "                m.chgCoeff(st_dyns[it * N + n], x[-1], -1)\n",
    "                idx += 1\n",
    "\n",
    "            # Variables for duplicating the previous state\n",
    "            for c in range(N):  # Duplicates of previous ds variables\n",
    "                i = c\n",
    "                x.append(m.addVar(name='zx_ds_%d_%d' % (i, t),\n",
    "                                  vtype=gu.GRB.CONTINUOUS, lb=0, ub=C_s[i], obj=0.))\n",
    "                m.chgCoeff(zx_constrs[it * nzx + c], x[-1], 1)\n",
    "                m.chgCoeff(st_dyns[it * N + i], x[-1], -1)\n",
    "                idx += 1\n",
    "                den = np.sum([np.sum(self.nw.F[t][k][i, :]) for k in range(K + 1)])\n",
    "                if den > 0:\n",
    "                    for k in range(K + 1):\n",
    "                        for j in range(N):\n",
    "                            ds_coeff = float(self.nw.F[t][k][i, j]) / den\n",
    "                            m.chgCoeff(wd_constrs[it * N * N * (K + 1) +\n",
    "                                                  i * (N * (K + 1)) + j * (K + 1) + k],\n",
    "                                       x[-1], -ds_coeff)\n",
    "\n",
    "            for c in range(N, N + (N * K)):  # Duplicates of previous q vars\n",
    "                posn = c - N\n",
    "                n, k = divmod(posn, K)\n",
    "                x.append(m.addVar(name='zx_q_%d_%d_%d' % (n, k, t),\n",
    "                                  vtype=gu.GRB.CONTINUOUS, lb=0, ub=self.nw.nr_bikes, obj=0.))\n",
    "                m.chgCoeff(zx_constrs[it * nzx + c], x[-1], 1)\n",
    "                if k == 0:\n",
    "                    m.chgCoeff(st_dyns[it * N + n], x[-1], -1)\n",
    "                else:\n",
    "                    m.chgCoeff(q_constrs[it * N * K + n * K + (k - 1)], x[-1], -1)\n",
    "                idx += 1\n",
    "\n",
    "        # Constant offset to objective function\n",
    "        m.setAttr('ObjCon', all_demand_lost_cost)\n",
    "        # Remove all wd_constrs entries (which enforce proportional sharing of demand)\n",
    "        for c in wd_constrs:\n",
    "            m.remove(c)\n",
    "        m.update()\n",
    "        t2 = time.time()\n",
    "\n",
    "        print(\"Stage 2 model created in %.3f s.\" % (t2 - t1))\n",
    "        if print_stats:\n",
    "            n_continuous = len([v for v in m.getVars() if v.vtype == gu.GRB.CONTINUOUS])\n",
    "            n_binary = len([v for v in m.getVars() if v.vtype == gu.GRB.BINARY])\n",
    "            n_integer = len([v for v in m.getVars() if v.vtype == gu.GRB.INTEGER])\n",
    "            n_constraints = len(m.getConstrs())\n",
    "            print(\"  %d vars (%d cont, %d binary, %d int), %d constraints.\" % \\\n",
    "                  (len(x), n_continuous, n_binary, n_integer, n_constraints))\n",
    "            print(\"  Initialized the model with a demand of %d customers.\" % len(self.w_indices))\n",
    "\n",
    "        return m, [st_dyns, wd_constrs, q_constrs, zx_constrs], x\n",
    "\n",
    "    def resample_s2_costs(self):\n",
    "        cost_params = self.cost_params\n",
    "        ldc = cost_params['lost demand cost']\n",
    "        ldc_spread_low = cost_params['lost demand cost spread low']\n",
    "        ldc_spread_high = cost_params['lost demand cost spread high']\n",
    "        print(\"  There are %d w-variables in the model.\" % len(self.w_indices))\n",
    "        for idx in self.w_indices:\n",
    "            value = np.random.uniform(low=ldc_spread_low * ldc,\n",
    "                                      high=ldc_spread_high * ldc)  # Trip value\n",
    "            # assert self.x_s2[idx].getAttr('VarName')[:2] == \"w_\"  # Check we're looking at a w var\n",
    "            self.x_s2[idx].setAttr('obj', -value)\n",
    "        self.m_s2.update()\n",
    "\n",
    "    def resample_s2_demand(self, deterministic=False, mute=False):\n",
    "        N, V, K, T = self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps, self.T\n",
    "        cost_params = self.cost_params\n",
    "        ldc = cost_params['lost demand cost']\n",
    "        ldc_spread_low = cost_params['lost demand cost spread low']\n",
    "        ldc_spread_high = cost_params['lost demand cost spread high']\n",
    "        t1 = time.time()\n",
    "        for idx in self.w_indices[::-1]:  # Step back through list deleting x from model and list\n",
    "            # assert self.x_s2[idx].getAttr('VarName')[:2] == \"w_\", self.x_s2[idx].getAttr('VarName')  # Check we're looking at a w var\n",
    "            self.m_s2.remove(self.x_s2[idx])\n",
    "            del self.x_s2[idx]\n",
    "        self.m_s2.update()\n",
    "\n",
    "        self.w_indices, idx = [], len(self.m_s2.getVars())\n",
    "        self.w_vars_added = [0] * self.T\n",
    "        all_demand_lost_cost = 0\n",
    "        m, x = self.m_s2, self.x_s2,\n",
    "        st_dyns, wd_constrs, q_constrs = self.c_list_s2[0], self.c_list_s2[1], self.c_list_s2[2]\n",
    "        # Re-generate new demand\n",
    "        for t in range(1, T + 1):\n",
    "            it = t - 1\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    for k in [0]:  # Customer actions w\n",
    "                        if deterministic:\n",
    "                            dem = int(np.rint(self.nw.F[t][k][i, j]))\n",
    "                        else:\n",
    "                            dem = np.random.poisson(self.nw.F[t][k][i, j])\n",
    "                        for d in range(dem):\n",
    "                            if deterministic:\n",
    "                                value = 0.5 * (ldc_spread_low + ldc_spread_high)\n",
    "                            else:\n",
    "                                value = np.random.uniform(low=ldc_spread_low * ldc,\n",
    "                                                          high=ldc_spread_high * ldc)  # Trip value\n",
    "                            x.append(m.addVar(name=\"w_%d_%d_%d_%d_%d\" % (i, j, k, t, d),\n",
    "                                              vtype=gu.GRB.CONTINUOUS, lb=0, ub=1, obj=-value))\n",
    "                            all_demand_lost_cost += value  # Since coefficients are -ve\n",
    "                            if i != j:\n",
    "                                m.chgCoeff(st_dyns[it * N + i], x[-1], 1)\n",
    "                                m.chgCoeff(st_dyns[it * N + j], x[-1], -1)\n",
    "                            # m.chgCoeff(wd_constrs[it * (N * N * (K + 1)) +\n",
    "                            #                       i * (N * (K + 1)) +\n",
    "                            #                       j * (K + 1) +\n",
    "                            #                       k], x[-1], 1)\n",
    "                            self.w_indices.append(idx)\n",
    "                            idx += 1\n",
    "                        self.w_vars_added[it] += dem\n",
    "                    for k in range(1, K + 1):  # Customer actions w\n",
    "                        if deterministic:\n",
    "                            dem = int(np.rint(self.nw.F[t][k][i, j]))\n",
    "                        else:\n",
    "                            dem = np.random.poisson(self.nw.F[t][k][i, j])\n",
    "                        for d in range(dem):\n",
    "                            value = np.random.uniform(low=ldc_spread_low * ldc,\n",
    "                                                      high=ldc_spread_high * ldc)  # Trip value\n",
    "                            x.append(m.addVar(name=\"w_%d_%d_%d_%d_%d\" % (i, j, k, t, d),\n",
    "                                              vtype=gu.GRB.CONTINUOUS, lb=0, ub=1, obj=-value))\n",
    "                            all_demand_lost_cost += value\n",
    "                            m.chgCoeff(st_dyns[it * N + i], x[-1], 1)\n",
    "                            # m.chgCoeff(wd_constrs[it * (N * N * (K + 1)) +\n",
    "                            #                       i * (N * (K + 1)) + j * (K + 1) + k], x[-1], 1)\n",
    "                            m.chgCoeff(q_constrs[it * N * K + j * K + (k - 1)], x[-1], -1)\n",
    "                            self.w_indices.append(idx)\n",
    "                            idx += 1\n",
    "                        self.w_vars_added[it] += dem\n",
    "        m.setAttr('ObjCon', all_demand_lost_cost)\n",
    "        m.update()\n",
    "        t2 = time.time()\n",
    "        if not mute:\n",
    "            print(\"  Resampled S2 demand in %.3f s: new demand is %d customers\" % \\\n",
    "                  (t2 - t1, len(self.w_indices)))\n",
    "\n",
    "    def eval_no_action_cost(self):\n",
    "        N, V, T, i = self.nw.nr_regions, self.nw.nr_vehicles, self.T, self.instance_no\n",
    "        self.set_s2_constr_rhs(s1_sol_vec=None, mute=True)\n",
    "        self.ub_no_action, self.stats_no_action = self.estimate_costs(first_stage_cost=0)\n",
    "        print(\"Mean cost with no action is %.3f; mean service rate is %.1f%%.\" % \\\n",
    "              (self.ub_no_action['cost'], self.stats_no_action['sr'] * 100))\n",
    "        df_entry = {'N': np.rint(N), 'V': np.rint(V), 'T': np.rint(T), 'Inst.': np.rint(i), 'k': 0,\n",
    "                    'Cost': np.round(self.ub_no_action['cost'], 6),\n",
    "                    'SR': np.round(self.stats_no_action['sr'] * 100, 6)}\n",
    "        self.results_df = self.results_df.append(df_entry, ignore_index=True)\n",
    "        self.results_df.to_csv('output/stats_N%d_V%d_T%d_i%d' % (N, V, T, i) +\n",
    "                               self.results_label + '.csv')\n",
    "\n",
    "    def estimate_costs(self, first_stage_cost, deterministic_s2=False):\n",
    "        print(\"  Estimating S2 cost...\")\n",
    "        t1 = time.time()\n",
    "        n_samples = self.alg_params['cost_eval_samples']\n",
    "        cost_list = np.zeros((n_samples,), dtype=float)\n",
    "        f_sum_list = np.zeros((n_samples,), dtype=float)\n",
    "        uf_sum_list = np.zeros((n_samples,), dtype=float)\n",
    "        f_value_list = np.zeros((n_samples,), dtype=float)\n",
    "        uf_value_list = np.zeros((n_samples,), dtype=float)\n",
    "        for i in range(n_samples):\n",
    "            # Measure cost and solutions stats for each of the samples\n",
    "            # np.random.seed(i)\n",
    "            self.resample_s2_demand(deterministic=deterministic_s2, mute=False)\n",
    "            cost_i, _, _, _ = self.optimize_stage(stage=2, mute=True)\n",
    "            cost_list[i] = cost_i + first_stage_cost\n",
    "            stats = self.s2_solution_stats()\n",
    "            f_sum_list[i] = stats['Fulfilled demand']\n",
    "            uf_sum_list[i] = stats['Unfulfilled demand']\n",
    "            f_value_list[i] = stats['Fulfilled value']\n",
    "            uf_value_list[i] = stats['Unfulfilled value']\n",
    "        t2 = time.time()\n",
    "        # Build dictionaries summarising cost and solution stats\n",
    "        ub = {'cost': np.mean(cost_list), 'sd': np.sqrt(np.var(cost_list)),\n",
    "              '5pc': np.percentile(cost_list, 5), '95pc': np.percentile(cost_list, 95)}\n",
    "        stats_out = {'f_sum': np.sum(f_sum_list), 'uf_sum': np.sum(uf_sum_list),\n",
    "                     'sr': np.sum(f_sum_list) / (np.sum(f_sum_list) + np.sum(uf_sum_list)),\n",
    "                     'time': t2-t1}\n",
    "\n",
    "        print(\"  MC evaluation of S2 cost (%d samples) took %.3f s.\" % (n_samples, t2 - t1))\n",
    "        print(\"    Mean service rate: %.1f%%\" % (stats_out['sr'] * 100.))\n",
    "\n",
    "        return ub, stats_out\n",
    "\n",
    "    def set_s1_initial_state(self):\n",
    "        N, V, K = self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps\n",
    "\n",
    "        vehicle_flow_mat = np.zeros((N, N), dtype=int)\n",
    "        bike_on_vehicle_flow_mat = np.zeros((N, N), dtype=int)\n",
    "\n",
    "        for loc, z0_val in enumerate(self.nw.z_0[:N * V]):\n",
    "            v_location, vehicle_id = divmod(loc, V)\n",
    "            vehicle_flow_mat[v_location, v_location] += z0_val\n",
    "            bike_on_vehicle_flow_mat[v_location, v_location] += self.nw.dv_0[vehicle_id]\n",
    "\n",
    "        # x0 = []\n",
    "        # for n in range(N):  # ds\n",
    "        #     x0.append(np.float(self.nw.ds_0[n]))  # Initial fill level of stations\n",
    "        # for i in range(N):  # dv\n",
    "        #     for j in range(N):\n",
    "        #         x0.append(bike_on_vehicle_flow_mat[i, j])  # Bikes currently being transported\n",
    "        # for i in range(N):\n",
    "        #     for j in range(N):\n",
    "        #         x0.append(vehicle_flow_mat[i, j])  # Number of vehicles just arrived from i to j\n",
    "\n",
    "        #  Set RHS of constraint equating the duplicate x_t-1 (xz in the optimization vector) to x0\n",
    "        m = self.m_s1\n",
    "        st_dyns = self.c_list_s1[0]\n",
    "        for n in range(N):\n",
    "            st_dyns[n].setAttr('RHS', np.rint(self.nw.ds_0[n]))\n",
    "        z_dyns = self.c_list_s1[2]\n",
    "        for j in range(N):\n",
    "            flow_to_j = 0\n",
    "            for i in range(N):\n",
    "                flow_to_j += vehicle_flow_mat[i, j]\n",
    "            z_dyns[j].setAttr('RHS', flow_to_j)\n",
    "        flow_dyns = self.c_list_s1[3]\n",
    "        for j in range(N):\n",
    "            flow_to_j = 0\n",
    "            for i in range(N):\n",
    "                flow_to_j += bike_on_vehicle_flow_mat[i, j]\n",
    "            flow_dyns[j].setAttr('RHS', flow_to_j)\n",
    "\n",
    "        # nzx = N + (N * N) + (N * N)  # ds, dv, z\n",
    "        # zx_constrs = self.c_list_s1[4]\n",
    "        # for c in range(nzx):\n",
    "        #     if np.abs(np.rint(x0[c]) - x0[c]) > 1e-4:  # Check for non-integer x0\n",
    "        #         print(\"x_l[%d]:\" % c, x0[c]\n",
    "        #         raise SystemExit()\n",
    "        #     zx_constrs[c].setAttr('RHS', np.rint(x0[c]))\n",
    "        m.update()\n",
    "\n",
    "    def set_s2_constr_rhs(self, s1_sol_vec=None, mute=True, really_solved_s1=False):\n",
    "        \"\"\"Set RHS of constraints in S2 model to reflect (i) initial state of system, and (ii) the\n",
    "        effect of S1 y decisions. Note that for (i) this only updates constraints to reflect initial\n",
    "        fill level of stations, and not queues of customers en route to stations (variables q).\n",
    "\n",
    "        :param s1_sol_vec: Stage 1 decision vector\n",
    "        :param mute: Hide printed description of the effect of the Stage 1 y-decisions\n",
    "        :param really_solved_s1: True if S1 sol'n was really optimized and not just randomly chosen\n",
    "        :return: nothing (updates model in place)\n",
    "        \"\"\"\n",
    "        T, N, V, K = self.T, self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps\n",
    "        m = self.m_s2\n",
    "        st_dyn_constrs = self.c_list_s2[0]\n",
    "        if s1_sol_vec is not None:\n",
    "            if self.alg_params['random_s1'] and not really_solved_s1:\n",
    "                n_x1_per_t = None\n",
    "            else:\n",
    "                assert divmod(len(s1_sol_vec), T)[1] == 0  # Length of opt vec should be a mult of T\n",
    "                n_x1_per_t = len(s1_sol_vec) / T\n",
    "                assert n_x1_per_t == self.vstage_s1\n",
    "            for t in range(1, T + 1):\n",
    "                it = t - 1\n",
    "                for n in range(N):\n",
    "                    if self.alg_params['random_s1'] and not really_solved_s1:\n",
    "                        delta_y = s1_sol_vec[n, it]  # s1_sol_vec is a N*T matrix in this case\n",
    "                    else:\n",
    "                        yplus_index = it * n_x1_per_t + (N + 2 * N * N) + (2 * n)\n",
    "                        yminus_index = it * n_x1_per_t + (N + 2 * N * N) + (2 * n + 1)\n",
    "                        delta_y = s1_sol_vec[yminus_index] - s1_sol_vec[yplus_index]\n",
    "                    if delta_y != 0 and not mute:\n",
    "                        print(\"    Delta y at t = %d, n = %d: %d\" % (t, n, delta_y))\n",
    "                    if t > 1:  # Update to account for S1 decision to deposit/remove bikes\n",
    "                        st_dyn_constrs[it * N + n].setAttr(\"RHS\", delta_y)\n",
    "                    else:  # Set initial condition accounting for initial number of bikes present\n",
    "                        st_dyn_constrs[n].setAttr(\"RHS\", delta_y + self.nw.ds_0[n])\n",
    "        else:  # No information about depositing or removing bikes, so just set initial fill level\n",
    "            for t in range(1, T + 1):\n",
    "                it = t - 1\n",
    "                for n in range(N):\n",
    "                    if t > 1:  # Update to account for S1 decision to deposit/remove bikes\n",
    "                        st_dyn_constrs[it * N + n].setAttr(\"RHS\", 0)\n",
    "                    else:  # Set initial condition accounting for initial number of bikes present\n",
    "                        st_dyn_constrs[n].setAttr(\"RHS\", 0 + self.nw.ds_0[n])\n",
    "        m.update()\n",
    "\n",
    "    def step_size(self, iteration):\n",
    "        if self.alg_params['ss_rule'] == '1/k':\n",
    "            return min(1.0, self.alg_params['1k_const'] / iteration)\n",
    "        elif self.alg_params['ss_rule'] == 'const':\n",
    "            return self.alg_params['ss_const']\n",
    "        elif self.alg_params['ss_rule'] == 'PRT':  # As suggested by Powell-Ruszczynksi-Topaloglu.\n",
    "            return 20.0 / (40.0 + iteration)\n",
    "        else:\n",
    "            print(\"Unrecognised step size rule: \" + self.alg_params['ss_rule'])\n",
    "            raise SystemExit()\n",
    "\n",
    "    def project_vf(self, vf_in):\n",
    "        assert len(vf_in.shape) == 3, \"Value function array is %d-dimensional!\" % len(vf_in.shape)\n",
    "        (nt, nr, nx) = vf_in.shape\n",
    "        n_projs = nt * nr  # Number of value functions to project\n",
    "        t1 = time.time()\n",
    "        solver_time = 0.\n",
    "        vf_out = np.zeros((nt, nr, nx), dtype=float)\n",
    "        for t in range(nt):\n",
    "            for r in range(nr):\n",
    "                vf_out[t, r, :], runtime = self.unit_vf_projection(vf_in[t, r, :])\n",
    "                solver_time += runtime\n",
    "        t2 = time.time()\n",
    "        # print(\"  Took %.3f s for %d VF projections (mean: %.1f us of which %.1f us solving).\" % \\\n",
    "        #       (t2 - t1, n_projs, (t2 - t1)/n_projs * 1e6, solver_time/n_projs * 1e6)\n",
    "        return vf_out\n",
    "\n",
    "    def unit_vf_projection(self, v_in):\n",
    "        m = self.vf_proj_m\n",
    "        for i, zi in enumerate(v_in):\n",
    "            self.vf_proj_x[i].setAttr(\"Obj\", -zi)\n",
    "        m.optimize()\n",
    "        if m.status in [2, 9, 11, 12]:\n",
    "            # print(\"Solved in %.1f us, status %d\" % (m.runtime * 1e6, m.status)\n",
    "            if m.status == 12:\n",
    "                print(\"Warning: Found numerical issues (status 12)\")\n",
    "            v_proj = [v.X for v in self.vf_proj_x]\n",
    "            return v_proj, m.runtime\n",
    "        else:\n",
    "            print(\"Projection failed! Status: %d\" % m.status)\n",
    "            raise SystemExit()\n",
    "\n",
    "    def setup_unit_projection_model(self, concave=False, max_slope=gu.GRB.INFINITY):\n",
    "        m = gu.Model(\"Projection\")\n",
    "        m.params.outputflag = 0\n",
    "        m.params.optimalitytol = 1e-6\n",
    "\n",
    "        x = []\n",
    "        qe = gu.QuadExpr()\n",
    "        constr_sense = gu.GRB.LESS_EQUAL if concave else gu.GRB.GREATER_EQUAL\n",
    "        for i in range(-self.alg_params['max_dev'], self.alg_params['max_dev']):\n",
    "            x.append(m.addVar(name=\"v_%d\" % i, lb=-max_slope, ub=max_slope,\n",
    "                              vtype=gu.GRB.CONTINUOUS, obj=0.))\n",
    "            m.update()\n",
    "            qe += 0.5 * x[-1] * x[-1]\n",
    "            if i > -self.alg_params['max_dev']:\n",
    "                m.addConstr(x[-1] - x[-2], constr_sense, 0)\n",
    "        m.setObjective(qe)\n",
    "        return m, x\n",
    "\n",
    "    def generate_xi(self, vf_old, s1_x, lambdas):\n",
    "        \"\"\"Generate gradient direction based on lagrange multipliers of second stage problem\n",
    "\n",
    "        :param vf_old: Old VF\n",
    "        :param s1_x: S1 decision vector\n",
    "        :param lambdas: Vector of Lagrange multipliers\n",
    "        :return: xi\n",
    "        \"\"\"\n",
    "        T, N, max_dev = self.T, self.nw.nr_regions, self.alg_params['max_dev']\n",
    "        xi = np.zeros((T, N, 2 * max_dev))\n",
    "\n",
    "        if self.alg_params['random_s1']:  # Random S1 decision\n",
    "            for it, n in itertools.product(range(T), range(N)):\n",
    "                grad_posn = int(s1_x[n, it]) + max_dev\n",
    "                if 0 <= grad_posn <= 2 * max_dev - 1:\n",
    "                    xi[it, n, grad_posn] = lambdas[it * N + n] - vf_old[it, n, grad_posn]\n",
    "                else:\n",
    "                    print(\"t = %d, n = %d: Wanted to modify gradient at pos'n %d (out of bounds)!\" \\\n",
    "                        % (it + 1, n, grad_posn))\n",
    "        else:  # Optimization-based solution to S1\n",
    "            nx1_per_t = len(s1_x) / T\n",
    "            assert nx1_per_t == self.vstage_s1\n",
    "            for it, n in itertools.product(range(T), range(N)):\n",
    "                # Fill level implied by S1 solution, which doesn't account for customer actions\n",
    "                y_minus_nt = s1_x[it * nx1_per_t + N + (N * N) + (N * N) + 2 * n + 1]\n",
    "                y_plus_nt = s1_x[it * nx1_per_t + N + (N * N) + (N * N) + 2 * n]\n",
    "                # Determine at which integer breakpoint to modify VF approximation for this t, n\n",
    "                grad_posn = int(y_minus_nt - y_plus_nt) + max_dev\n",
    "                if 0 <= grad_posn <= 2 * max_dev - 1:\n",
    "                    xi[it, n, grad_posn] = lambdas[it * N + n] - vf_old[it, n, grad_posn]\n",
    "                else:\n",
    "                    print(\"t = %d, n = %d: Wanted to modify gradient at pos'n %d (out of bounds)!\" \\\n",
    "                        % (it + 1, n, grad_posn))\n",
    "        return xi\n",
    "\n",
    "    def print_s1_solution(self, opt_vec):\n",
    "        N, V, K, T = self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps, self.T\n",
    "\n",
    "        opt_vec_series = [opt_vec[(t * self.vstage_s1):(t+1) * self.vstage_s1] for t in range(T)]\n",
    "        assert np.sum(len(ov) for ov in opt_vec_series) == len(opt_vec)\n",
    "\n",
    "        def all_integer_valued(list_in):\n",
    "            for v in list_in:\n",
    "                if np.abs(v - np.rint(v)) > 1e-4:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        print(\"Solution stats:\")\n",
    "\n",
    "        # Load/unload actions\n",
    "        loaded_or_unloaded_something = False\n",
    "        y_index = N + (N * N) + (N * N)\n",
    "        for it, vec in enumerate(opt_vec_series):\n",
    "            t = it + 1\n",
    "            for n in range(N):\n",
    "                yplus, yminus = vec[y_index + 2 * n], vec[y_index + 2 * n + 1]\n",
    "                if yplus > 0:\n",
    "                    if not loaded_or_unloaded_something:\n",
    "                        print(\"  Bike load/unload actions:\")\n",
    "                    loaded_or_unloaded_something = True\n",
    "                    print(\"    t = %d, loaded %d bikes onto vehicles at station %d\" % \\\n",
    "                          (t, yplus - yminus, n))\n",
    "                elif yminus > 0:\n",
    "                    if not loaded_or_unloaded_something:\n",
    "                        print(\"  Bike load/unload actions:\")\n",
    "                    loaded_or_unloaded_something = True\n",
    "                    print(\"    t = %d, unloaded %d bikes from vehicles at station %d\" % \\\n",
    "                          (t, yminus - yplus, n))\n",
    "        if not loaded_or_unloaded_something:\n",
    "            print(\"  No bikes loaded or unloaded from vehicles.\")\n",
    "\n",
    "        # Station fill levels: same for both 'flow' and 'vehicles' model form.\n",
    "        if loaded_or_unloaded_something:\n",
    "            print(\"  Station fill levels before accounting for customer movements:\")\n",
    "            station_fill_trajs = [[] for _ in range(N)]\n",
    "            for n in range(N):\n",
    "                for vec in opt_vec_series:\n",
    "                    station_fill_trajs[n].append(vec[n])\n",
    "                print(\"    Station %d:\" % n, [int(self.nw.ds_0[n])], \\\n",
    "                    [int(a) for a in station_fill_trajs[n]])\n",
    "\n",
    "        # Vehicle flows:\n",
    "        z_index = N + (N * N)\n",
    "        a_vehicle_moved = False\n",
    "        for it, vec in enumerate(opt_vec_series):\n",
    "            t = it + 1\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    flow = vec[z_index + i * N + j]\n",
    "                    if flow > 0 and all_integer_valued([flow]):\n",
    "                        if i == j:\n",
    "                            pass\n",
    "                            # print(\"    t = %d, staying at %d: %d\" % (t, i, flow)\n",
    "                        else:\n",
    "                            if not a_vehicle_moved:\n",
    "                                print(\"  Vehicle movements:\")\n",
    "                            a_vehicle_moved = True\n",
    "                            print(\"    t = %d, %d to %d: %d\" % (t, i, j, flow))\n",
    "                    elif flow > 0:\n",
    "                        if i == j:\n",
    "                            pass\n",
    "                            # print(\"    t = %d, staying at %d: %.2f\" % (t, i, flow)\n",
    "                        else:\n",
    "                            if not a_vehicle_moved:\n",
    "                                print(\"  Vehicle movements:\")\n",
    "                            a_vehicle_moved = True\n",
    "                            print(\"    t = %d, %d to %d: %.2f\" % (t, i, j, flow))\n",
    "        if not a_vehicle_moved:\n",
    "            print(\"  No vehicle movements.\")\n",
    "\n",
    "        # Bike flows\n",
    "        if loaded_or_unloaded_something:\n",
    "            dv_index = N\n",
    "            print(\"  Nonzero bike flows:\")\n",
    "            for it, vec in enumerate(opt_vec_series):\n",
    "                t = it + 1\n",
    "                for i in range(N):\n",
    "                    for j in range(N):\n",
    "                        flow = vec[dv_index + i * N + j]\n",
    "                        if flow > 1e-4 and all_integer_valued([flow]):\n",
    "                            if i == j:\n",
    "                                print(\"    t = %d, staying at %d: %d\" % (t, i, flow))\n",
    "                            else:\n",
    "                                print(\"    t = %d, %d to %d: %d\" % (t, i, j, flow))\n",
    "                        elif flow > 1e-4:\n",
    "                            if i == j:\n",
    "                                print(\"    t = %d, staying at %d: %.2f\" % (t, i, flow))\n",
    "                            else:\n",
    "                                print(\"    t = %d, %d to %d: %.2f\" % (t, i, j, flow))\n",
    "\n",
    "    def print_s2_solution(self, opt_vec_series):\n",
    "        N, V, K = self.nw.nr_regions, self.nw.nr_vehicles, self.nw.nr_lag_steps\n",
    "\n",
    "        assert len(opt_vec_series) == self.T\n",
    "\n",
    "        def all_integer_valued(list_in):\n",
    "            for v in list_in:\n",
    "                if np.abs(v - np.rint(v)) > 1e-4:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        print(\"Solution stats, '\" + self.model_form + \"' form:\")\n",
    "\n",
    "        # Unfulfilled customer demand: same for 'flow' and 'vehicles' except for vector index.\n",
    "        print(\"  Fulfilled demand:\")\n",
    "        w_index = N + (N * N) if self.model_form == 'flow' else N + V\n",
    "        f_sum = 0\n",
    "        for it, vec in enumerate(opt_vec_series):\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    for k in range(K + 1):\n",
    "                        t = it + 1\n",
    "                        w = vec[w_index + i * (N * (K + 1)) + j * (K + 1) + k]\n",
    "                        f = self.nw.F[t][k][i, j]\n",
    "                        if np.abs(f - w) <= 1e-5 and w >= 1e-5:\n",
    "                            # if all_integer_valued([f, w]):\n",
    "                            #     print(\"    w=%d at t = %d, %d -> %d (k = %d)\" % (w, t, i, j, k)\n",
    "                            # else:\n",
    "                            #     print(\"    w=%.2f at t = %d, %d -> %d (k = %d)\" % (w, t, i, j, k)\n",
    "                            f_sum += w\n",
    "        print(\"    Total:\", f_sum)\n",
    "        print(\"  Lost demand:\")\n",
    "        uf_sum = 0\n",
    "        for it, vec in enumerate(opt_vec_series):\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    for k in range(K + 1):\n",
    "                        t = it + 1\n",
    "                        w = vec[w_index + i * (N * (K + 1)) + j * (K + 1) + k]\n",
    "                        f = self.nw.F[t][k][i, j]\n",
    "                        if np.abs(f - w) > 1e-5:\n",
    "                            if all_integer_valued([f, w]):\n",
    "                                print(\"    %d (f=%d, w=%d) at t = %d, %d -> %d (k = %d)\" % \\\n",
    "                                      (f - w, f, w, t, i, j, k))\n",
    "                            else:\n",
    "                                print(\"    %.2f (f=%.2f, w=%.2f) at t = %d, %d -> %d (k = %d)\" % \\\n",
    "                                      (f - w, f, w, t, i, j, k))\n",
    "                            uf_sum += f - w\n",
    "        print(\"    Total:\", uf_sum)\n",
    "\n",
    "        # Station fill levels: same for both 'flow' and 'vehicles' model form.\n",
    "        print(\"  Station fill levels:\")\n",
    "        station_fill_trajs = [[] for _ in range(N)]\n",
    "        for n in range(N):\n",
    "            for vec in opt_vec_series:\n",
    "                station_fill_trajs[n].append(vec[n])\n",
    "            print(\"    Station %d:\" % n, [int(self.x0[n])], \\\n",
    "                [int(a) for a in station_fill_trajs[n]])\n",
    "\n",
    "        # Vehicle flows:\n",
    "        print(\"  Vehicle movements:\")\n",
    "        z_index = N + (N * N) + (K+1) * N*N if self.model_form == 'flow' else N + V + (K+1) * N*N\n",
    "        for it, vec in enumerate(opt_vec_series):\n",
    "            t = it + 1\n",
    "            if self.model_form == 'flow':\n",
    "                for i in range(N):\n",
    "                    for j in range(N):\n",
    "                        flow = vec[z_index + i * N + j]\n",
    "                        if flow > 0 and all_integer_valued([flow]):\n",
    "                            if i == j:\n",
    "                                print(\"    t = %d, staying at %d: %d\" % (t, i, flow))\n",
    "                            else:\n",
    "                                print(\"    t = %d, %d to %d: %d\" % (t, i, j, flow))\n",
    "                        elif flow > 0:\n",
    "                            if i == j:\n",
    "                                print(\"    t = %d, staying at %d: %.2f\" % (t, i, flow))\n",
    "                            else:\n",
    "                                print(\"    t = %d, %d to %d: %.2f\" % (t, i, j, flow))\n",
    "            else:\n",
    "                for v in range(V):\n",
    "                    for i in range(N):\n",
    "                        for j in range(N):\n",
    "                            flow = vec[z_index + i * N * V + j * V + v]\n",
    "                            if flow > 0 and all_integer_valued([flow]):\n",
    "                                if i == j:\n",
    "                                    print(\"    v%d, t = %d, staying at %d: %d\" % (v, t, i, flow))\n",
    "                                else:\n",
    "                                    print(\"    v%d, t = %d, %d to %d: %d\" % (v, t, i, j, flow))\n",
    "                            elif flow > 0:\n",
    "                                if i == j:\n",
    "                                    print(\"    v%d, t = %d, staying at %d: %.2f\" % (v, t, i, flow))\n",
    "                                else:\n",
    "                                    print(\"    v%d, t = %d, %d to %d: %.2f\" % (v, t, i, j, flow))\n",
    "        # Load/unload actions\n",
    "        if self.model_form == 'flow':\n",
    "            y_index = N + N * N + N * N * (K + 1) + N * N\n",
    "            print (\"  Nonzero load/unload actions:\")\n",
    "            for it, vec in enumerate(opt_vec_series):\n",
    "                t = it + 1\n",
    "                for n in range(N):\n",
    "                    yplus, yminus = vec[y_index + 2 * n], vec[y_index + 2 * n + 1]\n",
    "                    if yplus > 0:\n",
    "                        print (\"    t = %d, loaded %d bikes onto vehicles at station %d\" % \\\n",
    "                              (t, yplus - yminus, n))\n",
    "                    elif yminus > 0:\n",
    "                        print (\"    t = %d, unloaded %d bikes from vehicles at station %d\" % \\\n",
    "                              (t, yminus - yplus, n))\n",
    "        else:\n",
    "            y_index = N + V + N * N * (K + 1) + N * N * V\n",
    "            print (\"  Nonzero load/unload actions:\")\n",
    "            for it, vec in enumerate(opt_vec_series):\n",
    "                t = it + 1\n",
    "                for v in range(V):\n",
    "                    for n in range(N):\n",
    "                        yplus = vec[y_index + 2 * n * V + 2 * v]\n",
    "                        yminus = vec[y_index + 2 * n * V + 2 * v + 1]\n",
    "                        if yplus > 0:\n",
    "                            print (\"    t = %d, v%d loaded %d bikes onto vehicles at station %d\" % \\\n",
    "                                  (t, v, yplus - yminus, n))\n",
    "                        elif yminus > 0:\n",
    "                            print (\"    t = %d, v%d unloaded %d bikes from vehicles at station %d\" % \\\n",
    "                                  (t, v, yminus - yplus, n))\n",
    "\n",
    "        # Passenger queues\n",
    "        q_index = N + V + N * N * (K + 1) + N * N * V + 2 * N * V \\\n",
    "            if self.model_form == 'vehicles' else N + N * N + N * N * (K + 1) + N * N + 2 * N\n",
    "        q_trajs = [[[] for _ in range(N)] for k in range(K)]\n",
    "        for it, vec in enumerate(opt_vec_series):\n",
    "            t = it + 1\n",
    "            for n in range(N):\n",
    "                for k in range(K):\n",
    "                    q_trajs[k][n].append(vec[q_index + n * K + k])\n",
    "        for k in range(1, K + 1):\n",
    "            print (\"  Station queues, k = %d:\" % k)\n",
    "            for n in range(N):\n",
    "                if all_integer_valued(q_trajs[k-1][n]):\n",
    "                    print (\"    Station %d:\" % n, [int(v) for v in q_trajs[k-1][n]])\n",
    "                else:\n",
    "                    print (\"    Station %d:\" % n, q_trajs[k-1][n])\n",
    "\n",
    "        # Bike and vehicle flows\n",
    "        dv_index = N\n",
    "        if self.model_form == 'flow':\n",
    "            print (\"  Nonzero bike flows:\")\n",
    "            for it, vec in enumerate(opt_vec_series):\n",
    "                t = it + 1\n",
    "                for i in range(N):\n",
    "                    for j in range(N):\n",
    "                        flow = vec[dv_index + i * N + j]\n",
    "                        if flow > 1e-4 and all_integer_valued([flow]):\n",
    "                            if i == j:\n",
    "                                print (\"    t = %d, staying at %d: %d\" % (t, i, flow))\n",
    "                            else:\n",
    "                                print (\"    t = %d, %d to %d: %d\" % (t, i, j, flow))\n",
    "                        elif flow > 1e-4:\n",
    "                            if i == j:\n",
    "                                print (\"    t = %d, staying at %d: %.2f\" % (t, i, flow))\n",
    "                            else:\n",
    "                                print (\"    t = %d, %d to %d: %.2f\" % (t, i, j, flow))\n",
    "        else:\n",
    "            dv_trajs = [[] for v in range(V)]\n",
    "            for it, vec in enumerate(opt_vec_series):\n",
    "                t = it + 1\n",
    "                for v in range(V):\n",
    "                    dv_trajs[v].append(vec[dv_index + v])\n",
    "            print (\"  Bikes carried by vehicles:\")\n",
    "            for v in range(V):\n",
    "                if all_integer_valued(dv_trajs[v]):\n",
    "                    print (\"    v%d:\" % v, [int(x) for x in dv_trajs[v]])\n",
    "                else:\n",
    "                    print (\"    v%d:\" % v, dv_trajs[v])\n",
    "\n",
    "    def s2_solution_stats(self):\n",
    "        opt_vec = self.x_s2\n",
    "        stats_dict = {}\n",
    "\n",
    "        # Unfulfilled customer demand\n",
    "        total_demand = len(self.w_indices)\n",
    "        f_sum = np.sum([opt_vec[idx].X for idx in self.w_indices])\n",
    "        uf_sum = total_demand - f_sum\n",
    "        f_value = np.sum([opt_vec[idx].obj for idx in self.w_indices if opt_vec[idx].X == 1])\n",
    "        uf_value = np.sum([opt_vec[idx].obj for idx in self.w_indices if opt_vec[idx].X == 0])\n",
    "        stats_dict['Fulfilled demand'], stats_dict['Unfulfilled demand'] = f_sum, uf_sum\n",
    "        stats_dict['Service rate'] = 100.0 * float(f_sum) / float(f_sum + uf_sum)\n",
    "        stats_dict['Fulfilled value'], stats_dict['Unfulfilled value'] = f_value, uf_value\n",
    "\n",
    "        return stats_dict\n",
    "\n",
    "    def plot_cost_estimates(self, suffix=''):\n",
    "        lb, ub, stats = self.lb, self.ub, self.stats\n",
    "        lbx, lby = [], []\n",
    "        for (k, v) in lb.iteritems():\n",
    "            lbx.append(int(k))\n",
    "            lby.append(float(v))\n",
    "        ubx, uby, ub5pc, ub95pc = [], [], [], []\n",
    "        for (k, v) in ub.iteritems():\n",
    "            ubx.append(int(k))\n",
    "            uby.append(float(v['cost']))\n",
    "            ub5pc.append(float(v['5pc']))\n",
    "            ub95pc.append(float(v['95pc']))\n",
    "        lbx, lby, ubx, uby = np.array(lbx), np.array(lby), np.array(ubx), np.array(uby)\n",
    "        ub5pc, ub95pc = np.array(ub5pc), np.array(ub95pc)\n",
    "        lbx_order = np.argsort(lbx)\n",
    "        lbx, lby = lbx[lbx_order], lby[lbx_order]\n",
    "        ubx_order = np.argsort(ubx)\n",
    "        ubx, uby, ub5pc, ub95pc = ubx[ubx_order], uby[ubx_order], ub5pc[ubx_order], ub95pc[ubx_order]\n",
    "        plt.figure()\n",
    "        plt.subplot(211)\n",
    "        # plt.plot(lbx, lby, 'r')\n",
    "        plt.plot(ubx, uby, 'b')\n",
    "        plt.plot(ubx, ub5pc, 'b--')\n",
    "        plt.plot(ubx, ub95pc, 'b--')\n",
    "        if self.ub_no_action is not None:\n",
    "            ubnay, ubna5pc, ubna95pc = self.ub_no_action['cost'], self.ub_no_action['5pc'], \\\n",
    "                self.ub_no_action['95pc']\n",
    "            plt.plot([np.min(ubx), np.max(ubx)], [ubnay, ubnay], 'g')\n",
    "            plt.plot([np.min(ubx), np.max(ubx)], [ubna5pc, ubna5pc], 'g--')\n",
    "            plt.plot([np.min(ubx), np.max(ubx)], [ubna95pc, ubna95pc], 'g--')\n",
    "        plt.xlim([np.min(ubx), np.max(ubx)])\n",
    "        plt.xlabel('Iteration $k$')\n",
    "        plt.ylabel('Cost estimate')\n",
    "        plt.title('%d stations, %d vehicles' % (self.nw.nr_regions, self.nw.nr_vehicles))\n",
    "\n",
    "        stx, stsr = [], []\n",
    "        for (k, v) in stats.iteritems():\n",
    "            stx.append(int(k))\n",
    "            stsr.append(float(v['sr']))\n",
    "        stx, stsr = np.array(stx), np.array(stsr)\n",
    "        stx_order = np.argsort(stx)\n",
    "        stx, stsr = stx[stx_order], stsr[stx_order]\n",
    "        plt.subplot(212)\n",
    "        plt.plot(stx, stsr * 100., 'b')\n",
    "        if self.stats_no_action is not None:\n",
    "            plt.plot([np.min(stx), np.max(stx)],\n",
    "                     [self.stats_no_action['sr'] * 100., self.stats_no_action['sr'] * 100.], 'g')\n",
    "        plt.xlim([np.min(ubx), np.max(ubx)])\n",
    "        plt.xlabel('Iteration $k$')\n",
    "        plt.ylabel('Average service rate')\n",
    "        plt.title('Service rate')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('output/sr_N%d_V%d_T%d' % (self.nw.nr_regions, self.nw.nr_vehicles, self.T)\n",
    "                    + suffix + '.pdf')\n",
    "\n",
    "    def plot_vf_evolution(self, t_in=None, n_in=None, mode='all_tn', suffix=''):\n",
    "\n",
    "        k_max = len(self.vfpp)\n",
    "        plot_every = self.alg_params['plot_every']\n",
    "\n",
    "        ds_0, max_dev = self.nw.ds_0, self.alg_params['max_dev']\n",
    "\n",
    "        if mode == 'all_tn':\n",
    "            print (\"Plotting value function for all stations and time steps...\")\n",
    "            T, N = self.vfpp[0].shape[0], self.vfpp[0].shape[1]\n",
    "            plt.figure(figsize=(30, 2.5 * N))\n",
    "\n",
    "            # Determine y-axis scale\n",
    "            vpcs = np.cumsum(self.vf[-1], 2)  # Cumulative sum of projected value function\n",
    "            vpcs -= vpcs[:, :, max_dev - 1:max_dev]  # Treatment of axis 2 ensures broadcast works\n",
    "            max_v, min_v = min(np.max(vpcs), 20), max(np.min(vpcs), -20)\n",
    "            min_v_plot, max_v_plot = min_v - 0.02 * (max_v - min_v), max_v + 0.02 * (max_v - min_v)\n",
    "\n",
    "            for (i, it) in itertools.product(range(N), range(T)):\n",
    "                # vfppe = [np.squeeze(v[t_in, n_in, :]) for v in self.vfpp]\n",
    "                vfe = [np.squeeze(v[it, i, :]) for v in self.vf]  # VF evolution by iteration\n",
    "                plt.subplot(N, T, i * T + (it+1))\n",
    "                for k, sv in enumerate(vfe):\n",
    "                    assert len(sv) == 2 * max_dev\n",
    "                    vpc = np.cumsum(sv)\n",
    "                    if k_max < 20 or divmod(k, plot_every)[1] == 0:\n",
    "                        redeploys = [x for x in range(-max_dev, max_dev + 1)]\n",
    "                        val_rel_to_no_action = np.hstack((np.array([0]), vpc)) - vpc[max_dev - 1]\n",
    "                        plt.plot(redeploys, val_rel_to_no_action, 'b', alpha=0.2)\n",
    "                        plt.ylim([min_v_plot, max_v_plot])\n",
    "                    if k == k_max - 1:  # Last VF recorded\n",
    "                        redeploys = [x for x in range(-max_dev, max_dev + 1)]\n",
    "                        val_rel_to_no_action = np.hstack((np.array([0]), vpc)) - vpc[max_dev - 1]\n",
    "                        plt.plot(redeploys, val_rel_to_no_action, 'k')\n",
    "                        plt.ylim([min_v_plot, max_v_plot])\n",
    "\n",
    "                        # Add a marker showing the redeploy action (y- minus y+)\n",
    "                        if self.last_x1_sol is not None:\n",
    "                            s1_action = self.last_x1_sol[it * self.vstage_s1 +\n",
    "                                                         N + (N * N) + (N * N) + 2 * i + 1] - \\\n",
    "                                        self.last_x1_sol[it * self.vstage_s1 +\n",
    "                                                         N + (N * N) + (N * N) + 2 * i]\n",
    "                            plt.scatter([s1_action], [0],\n",
    "                                        s=60 if s1_action == 0 else 80,\n",
    "                                        c='r' if s1_action == 0 else 'g',\n",
    "                                        marker='d')  # More prominent marker if loaded/unloaded\n",
    "                plt.text(0, max_v_plot - 0.1 * (max_v_plot - min_v_plot),\n",
    "                         '$i = %d$, $t = %d$' % (i + 1, it + 1), ha='center', family='serif')\n",
    "                if i == 0:\n",
    "                    plt.title('t = %d' % (it + 1))\n",
    "                if it == 0:\n",
    "                    plt.ylabel('i = %d' % (i + 1))\n",
    "                if i == N - 1:\n",
    "                    plt.xlabel('$y_i^{-,t} - y_i^{+,t}$')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('output/vf__N%d_V%d_T%d_i%d' % (self.nw.nr_regions, self.nw.nr_vehicles,\n",
    "                                                        self.T, self.instance_no) + suffix + '.pdf')\n",
    "            plt.close()\n",
    "            print (\"  Done.\")\n",
    "        else:\n",
    "            assert t_in is not None and n_in is not None\n",
    "            vfppe = [np.squeeze(v[t_in, n_in, :]) for v in self.vfpp]\n",
    "            vfe = [np.squeeze(v[t_in, n_in, :]) for v in self.vf]\n",
    "            plt.figure()\n",
    "            for k, v in enumerate(vfppe):\n",
    "                nx = len(v)\n",
    "                vc = np.cumsum(v)\n",
    "                if divmod(k, plot_every)[1] == 0:\n",
    "                    plt.plot(range(nx + 1), np.hstack((np.array([0]), vc)), 'g',\n",
    "                             alpha=(k + 1.0) / k_max)\n",
    "            plt.savefig('output/vfpp_%d_%d.pdf' % (t_in, n_in))\n",
    "            plt.close()\n",
    "            plt.figure()\n",
    "            for k, v in enumerate(vfe):\n",
    "                nx = len(v)\n",
    "                vpc = np.cumsum(v)\n",
    "                if divmod(k, plot_every)[1] == 0:\n",
    "                    plt.plot(range(nx + 1), np.hstack((np.array([0]), vpc)), 'b',\n",
    "                             alpha=(k + 1.0) / k_max)\n",
    "            plt.savefig('output/vf_%d_%d.pdf' % (t_in, n_in))\n",
    "            plt.close()\n",
    "\n",
    "    def unrelax_s1(self, relax_or_unrelax='unrelax'):\n",
    "        \"\"\"\n",
    "        Un-relaxes a relaxed S1 model by setting routing and redeployment decisions to integers. Can\n",
    "        also relax an integer model by doing the reverse.\n",
    "        :param relax_or_unrelax: Can only take the values 'unrelax' or 'relax'\n",
    "        :return: Nothing\n",
    "        \"\"\"\n",
    "        t1 = time.time()\n",
    "        if relax_or_unrelax == 'unrelax':\n",
    "            for x in self.x_s1:\n",
    "                if x.varname[0] in ['y', 'z']:\n",
    "                    x.vtype = gu.GRB.INTEGER\n",
    "        elif relax_or_unrelax == 'relax':\n",
    "            print (\"Warning: re-relaxation of S1 model not properly implemented!\")\n",
    "            for x in self.x_s1:\n",
    "                if x.varname[0] in ['y', 'z']:\n",
    "                    x.vtype = gu.GRB.CONTINUOUS\n",
    "        else:\n",
    "            print (\"Unrecognised relax or unrelax option, \" + relax_or_unrelax)\n",
    "            raise SystemExit()\n",
    "        self.m_s1.update()\n",
    "        t2 = time.time()\n",
    "        if relax_or_unrelax == 'unrelax':\n",
    "            print (\"Unrelaxed S1 model in %.3f s.\" % (t2 - t1))\n",
    "        else:\n",
    "            print (\"(Re-)relaxed S1 model in %.3f s.\" % (t2 - t1))\n",
    "\n",
    "    @staticmethod\n",
    "    def print_non_zero_coeffs(c_list, m):\n",
    "        \"\"\"Print coefficients of constraints appearing in model m.\n",
    "\n",
    "        :param c_list: List of Gurobi constraint objects\n",
    "        :param m: Gurobi model\n",
    "        :return: Nothing. Prints output.\n",
    "        \"\"\"\n",
    "        for constr_to_test in c_list:\n",
    "            print(\"Coefficients for constraint\", constr_to_test.getAttr('ConstrName') + \":\")\n",
    "            for var in m.getVars():\n",
    "                varname = var.getAttr('VarName')\n",
    "                if m.getCoeff(constr_to_test, var) != 0:\n",
    "                    print(\" \", varname, m.getCoeff(constr_to_test, var))\n",
    "            print(\"  RHS:\", constr_to_test.getAttr('RHS'))\n",
    "            print(\"  Sense:\", constr_to_test.sense)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_constr_membership(var_name, m):\n",
    "        var = m.getVarByName(var_name)\n",
    "        for c in m.getConstrs():\n",
    "            if m.getCoeff(c, var) != 0:\n",
    "                SAModel.print_non_zero_coeffs([c], m)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_v_and_vp(v, vp, label=''):\n",
    "        plt.figure()\n",
    "        plt.subplot(211)\n",
    "        assert len(v) == len(vp)\n",
    "        nx = len(v)\n",
    "        vc = np.cumsum(v)\n",
    "        vpc = np.cumsum(vp)\n",
    "        plt.plot(range(nx+1), np.hstack((np.array([0]), vc)), 'g')\n",
    "        plt.plot(range(nx+1), np.hstack((np.array([0]), vpc)), 'b')\n",
    "        plt.subplot(212)\n",
    "        plt.plot(range(nx), v, 'g')\n",
    "        plt.plot(range(nx), vp, 'b')\n",
    "        plt.savefig('output/vfp' + label + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network: N=9, V=1, T=4, instance 1\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 1\n",
      "Creating network: N=9, V=3, T=4, instance 1\n",
      "Creating network: N=9, V=1, T=4, instance 2\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 2\n",
      "Creating network: N=9, V=3, T=4, instance 2\n",
      "Creating network: N=9, V=1, T=4, instance 3\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 3\n",
      "Creating network: N=9, V=3, T=4, instance 3\n",
      "Creating network: N=9, V=1, T=4, instance 4\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 4\n",
      "Creating network: N=9, V=3, T=4, instance 4\n",
      "Creating network: N=9, V=1, T=4, instance 5\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 5\n",
      "Creating network: N=9, V=3, T=4, instance 5\n",
      "Creating network: N=9, V=1, T=4, instance 6\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 6\n",
      "Creating network: N=9, V=3, T=4, instance 6\n",
      "Creating network: N=9, V=1, T=4, instance 7\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 7\n",
      "Creating network: N=9, V=3, T=4, instance 7\n",
      "Creating network: N=9, V=1, T=4, instance 8\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 8\n",
      "Creating network: N=9, V=3, T=4, instance 8\n",
      "Creating network: N=9, V=1, T=4, instance 9\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 9\n",
      "Creating network: N=9, V=3, T=4, instance 9\n",
      "Creating network: N=9, V=1, T=4, instance 10\n",
      "  Total demand is 0 trips; 0.00 trips/bike.\n",
      "Creating network: N=9, V=1, T=4, instance 10\n",
      "Creating network: N=9, V=3, T=4, instance 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BELKESSA\\AppData\\Local\\Temp\\ipykernel_13464\\1959513674.py:243: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  while int(sum(x_0)) > self.nr_bikes:\n",
      "C:\\Users\\BELKESSA\\AppData\\Local\\Temp\\ipykernel_13464\\1959513674.py:247: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  while int(sum(x_0)) < self.nr_bikes:\n",
      "C:\\Users\\BELKESSA\\AppData\\Local\\Temp\\ipykernel_13464\\1959513674.py:266: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  initial_regions.append(int(available_regions[r]))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\"\"\"Create a sequence of random network instances and store them in folders in network_data/\"\"\"\n",
    "n_v_array = {9: [1, 3], 16: [1, 5], 25: [1, 5, 9], 36: [1, 5, 11],\n",
    "             64: [1, 9, 15], 100: [1, 9, 19], 225: [1, 13, 25], 400: [1, 15, 35]}\n",
    "\n",
    "for n in [3]:  # Number of nodes n along the edge of the square grid\n",
    "    for T in [4]:  # Number of time steps T in planning horizon\n",
    "        for i in range(1, 11):  # Controls number of instances i and their labels\n",
    "            # Number of nodes\n",
    "            N = n * n\n",
    "            # Total number of bikes in system\n",
    "            B = N * 5\n",
    "            # Planning horizon\n",
    "            W = 6\n",
    "            # Time Horizon for trips\n",
    "            K = 2\n",
    "            # Station capacity\n",
    "            C_s = np.ceil(2. * B / N) * np.ones(N)\n",
    "            # Vehicle count and capacity\n",
    "            V = 1\n",
    "            vehicle_cap = 5\n",
    "            C_v = vehicle_cap * np.ones(V)\n",
    "            # Vehicle speed\n",
    "            vehicle_speed = 100. / n * 1.25\n",
    "\n",
    "            # Name and create target directory\n",
    "            directory = \"network_data/\"\n",
    "            network_folder = f\"{directory}N{N:03d}_V{V:02d}_T{T:02d}\"\n",
    "            if not os.path.exists(network_folder):\n",
    "                os.makedirs(network_folder)\n",
    "            filename = f\"{network_folder}/instance_{i:02d}\"\n",
    "            print(f\"Creating network: N={N}, V={V}, T={T}, instance {i}\")\n",
    "\n",
    "            # Generate network object\n",
    "            nw = SyntheticNetwork(N, V, C_s, C_v, B, T, W, K, vehicle_speed)\n",
    "            with open(f\"{filename}.pkl\", 'wb') as output:\n",
    "                pickle.dump(nw, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            for V in n_v_array[N]:\n",
    "                # Update network object for new V (don't generate new customer demand matrices)\n",
    "                nw.modify_nr_vehicles(V, vehicle_cap * np.ones(V))\n",
    "                # Name and create target directory\n",
    "                network_folder = f\"{directory}N{N:03d}_V{V:02d}_T{T:02d}\"\n",
    "                if not os.path.exists(network_folder):\n",
    "                    os.makedirs(network_folder)\n",
    "                filename = f\"{network_folder}/instance_{i:02d}\"\n",
    "                print(f\"Creating network: N={N}, V={V}, T={T}, instance {i}\")\n",
    "\n",
    "                # Save network object modified for new value of V\n",
    "                with open(f\"{filename}.pkl\", 'wb') as output:\n",
    "                    pickle.dump(nw, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing N=9, V=1, T=12, instance 1\n",
      "File network_data/N009_V01_T12/instance_01.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 1\n",
      "File network_data/N009_V03_T12/instance_01.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 2\n",
      "File network_data/N009_V01_T12/instance_02.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 2\n",
      "File network_data/N009_V03_T12/instance_02.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 3\n",
      "File network_data/N009_V01_T12/instance_03.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 3\n",
      "File network_data/N009_V03_T12/instance_03.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 4\n",
      "File network_data/N009_V01_T12/instance_04.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 4\n",
      "File network_data/N009_V03_T12/instance_04.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 5\n",
      "File network_data/N009_V01_T12/instance_05.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 5\n",
      "File network_data/N009_V03_T12/instance_05.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 6\n",
      "File network_data/N009_V01_T12/instance_06.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 6\n",
      "File network_data/N009_V03_T12/instance_06.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 7\n",
      "File network_data/N009_V01_T12/instance_07.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 7\n",
      "File network_data/N009_V03_T12/instance_07.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 8\n",
      "File network_data/N009_V01_T12/instance_08.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 8\n",
      "File network_data/N009_V03_T12/instance_08.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 9\n",
      "File network_data/N009_V01_T12/instance_09.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 9\n",
      "File network_data/N009_V03_T12/instance_09.pkl does not exist! Skipping.\n",
      "Testing N=9, V=1, T=12, instance 10\n",
      "File network_data/N009_V01_T12/instance_10.pkl does not exist! Skipping.\n",
      "Testing N=9, V=3, T=12, instance 10\n",
      "File network_data/N009_V03_T12/instance_10.pkl does not exist! Skipping.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "# Ensure required directories exist\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('vfs', exist_ok=True)\n",
    "\n",
    "# Define parameters\n",
    "cost_params = {\n",
    "    'lost demand cost': 1.0,\n",
    "    'vehicle movt cost': 1e-3,\n",
    "    'load cost': 1e-3,\n",
    "    'unload cost': 1e-3,\n",
    "    'lost bike cost': 20,\n",
    "    'created bike cost': 20,\n",
    "    'lost demand cost spread low': 0.5,\n",
    "    'lost demand cost spread high': 1.5\n",
    "}\n",
    "alg_params = {\n",
    "    'n_iter': 50,\n",
    "    'ss_rule': 'PRT',\n",
    "    'max_dev': 10,\n",
    "    '1k_const': 40,\n",
    "    'ss_const': 0.2,\n",
    "    'relax_s1': 'All z',\n",
    "    'plot_every': 10,\n",
    "    'cost_eval_samples': 100,\n",
    "    'eval_cost_every': 5,\n",
    "    'final_sol': True,\n",
    "    'final_sol_method': 'exact',\n",
    "    'save_iter_models': False,\n",
    "    'eval_cost_k': [10, 20, 50],\n",
    "    'random_s1': False,\n",
    "    'nominal_s2': False\n",
    "}\n",
    "\n",
    "T = 12  # Number of time steps\n",
    "\n",
    "# Define network configurations\n",
    "n_v_array = {\n",
    "    9: [1, 3],\n",
    "    16: [1, 5],\n",
    "    25: [1, 5, 9],\n",
    "    36: [1, 5, 11],\n",
    "    64: [1, 9, 15],\n",
    "    100: [1, 9, 19],\n",
    "    225: [1, 13, 25],\n",
    "    400: [1, 15, 35]\n",
    "}\n",
    "\n",
    "# Process network instances\n",
    "for N, i in product([9], range(1, 11)):\n",
    "    for V in n_v_array[N]:\n",
    "        print(f\"Testing N={N}, V={V}, T={T}, instance {i}\")\n",
    "        filename = f\"network_data/N{N:03d}_V{V:02d}_T{T:02d}/instance_{i:02d}.pkl\"\n",
    "        \n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'rb') as input_file:\n",
    "                nw = pickle.load(input_file)\n",
    "            nw.dv_0 = np.zeros((V, 1))\n",
    "\n",
    "            # Set up and evaluate the model\n",
    "            s = SAModel(nw, cost_params, alg_params, T, i, label='_regular')\n",
    "            s.eval_no_action_cost()\n",
    "            s.approx()\n",
    "        else:\n",
    "            print(f\"File {filename} does not exist! Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m()\n\u001b[0;32m     31\u001b[0m     dfl\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m---> 33\u001b[0m dc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuffix \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filelist)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files found, containing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dc)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Average results across network sizes, on the \"Inst.\" column.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BELKESSA\\AppData\\Local\\anaconda3\\envs\\env_fleet\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\BELKESSA\\AppData\\Local\\anaconda3\\envs\\env_fleet\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\BELKESSA\\AppData\\Local\\anaconda3\\envs\\env_fleet\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Configure Matplotlib for non-interactive backend if needed\n",
    "if os.environ.get('DISPLAY', '') == '' and platform.system() == 'Linux':\n",
    "    mpl.use('Agg')  # Use non-interactive Agg backend on Linux server\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Iterate through suffixes for processing\n",
    "for suffix in ['_regular', '_integer', '_halfinteger', '_det2s_corrected', '_random']:\n",
    "    # Import and concatenate results sheets\n",
    "    suffix_len = len(suffix)\n",
    "    filelist = [fname for fname in os.listdir('output')\n",
    "                if fname.startswith('stats') and fname.endswith(suffix + '.csv')]\n",
    "    dfl = []\n",
    "    for f in filelist:\n",
    "        df = pd.read_csv(os.path.join('output', f))\n",
    "        try:\n",
    "            base_sr = df.loc[df['k'].isin([0, '0.0']), 'SR'].iloc[0]\n",
    "            base_cost = df.loc[df['k'].isin([0, '0.0']), 'Cost'].iloc[0]\n",
    "            df['SR_rel'] = df['SR'] - base_sr\n",
    "            df['Cost_rel'] = df['Cost'] - base_cost\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file: {os.path.join('output', f)}\")\n",
    "            print(f\"Base SR and Cost not found. Exception: {e}\")\n",
    "            raise SystemExit()\n",
    "        dfl.append(df)\n",
    "\n",
    "    dc = pd.concat(dfl, ignore_index=True)\n",
    "    print(f\"Suffix {suffix}: {len(filelist)} files found, containing {len(dc)} records.\")\n",
    "\n",
    "    # Average results across network sizes, on the \"Inst.\" column.\n",
    "    iter_times = dc.loc[dc['Integer'] == 0.0].groupby(['N', 'V'])[['t1', 't2']].mean()\n",
    "    iter_times_std = dc.loc[dc['Integer'] == 0.0].groupby(['N', 'V'])[['t1', 't2']].std()\n",
    "    rec_count = dc.loc[(dc['Integer'] == 0.0) & (dc['k'] == 50)].groupby(['N', 'V'])['t1'].count()\n",
    "    print(rec_count)\n",
    "\n",
    "    try:\n",
    "        iter_csv = iter_times.merge(iter_times_std, on=['N', 'V'], suffixes=('_mean', '_std'))\n",
    "        print(iter_csv.head())\n",
    "    except KeyError as e:\n",
    "        print(iter_times)\n",
    "        print(iter_times_std)\n",
    "        print(f\"KeyError: {e}\")\n",
    "        raise SystemExit()\n",
    "\n",
    "    iter_csv.round(6).to_csv(f'output/iter_times{suffix}.csv')\n",
    "\n",
    "    grouped = dc.groupby(['N', 'V', 'k'])[['Cost', 'SR', 'Cost_rel', 'SR_rel']]\n",
    "    cost_sr = grouped.mean().dropna()\n",
    "    std_cost_sr = grouped.std().dropna()\n",
    "\n",
    "    mean_std_df = cost_sr.merge(std_cost_sr, on=['N', 'V', 'k'], suffixes=('_mean', '_std'))\n",
    "    mean_std_df.round(6).to_csv(f'output/mean_std_stats{suffix}.csv')\n",
    "\n",
    "    save_plots = False\n",
    "    if save_plots:\n",
    "        for N, sub_df in mean_std_df.groupby(level=0):\n",
    "            for V, sub_sub_df in sub_df.groupby(level=1):\n",
    "                try:\n",
    "                    k_list = [int(round(idx[2])) for idx in sub_sub_df.index.values]\n",
    "                    sr_mean_list = sub_sub_df['SR_rel_mean'].tolist()\n",
    "                    sr_std_list = sub_sub_df['SR_rel_std'].tolist()\n",
    "                    cost_mean_list = sub_sub_df['Cost_rel_mean'].tolist()\n",
    "                    cost_std_list = sub_sub_df['Cost_rel_std'].tolist()\n",
    "\n",
    "                    if suffix == '_integer':\n",
    "                        k_list = k_list[:-1]  # Adjust for extra iteration in '_integer'\n",
    "                        sr_mean_list = sr_mean_list[:-1]\n",
    "                        sr_std_list = sr_std_list[:-1]\n",
    "                        cost_mean_list = cost_mean_list[:-1]\n",
    "                        cost_std_list = cost_std_list[:-1]\n",
    "\n",
    "                    # Plot Service Rate\n",
    "                    plt.figure(figsize=(8, 4))\n",
    "                    plt.plot(k_list, sr_mean_list, 'k')\n",
    "                    plt.plot(k_list, np.array(sr_mean_list) + np.array(sr_std_list), 'k--')\n",
    "                    plt.plot(k_list, np.array(sr_mean_list) - np.array(sr_std_list), 'k--')\n",
    "                    plt.xlim([min(k_list), max(k_list)])\n",
    "                    plt.xlabel('Iteration $k$')\n",
    "                    plt.ylabel('Service rate increase (%)')\n",
    "                    plt.title(f'{N} nodes, {V} RV' + ('' if V == 1 else 's'))\n",
    "                    filename = f'output/sr_stats_{N}_{V}{suffix}.pdf'\n",
    "                    plt.tight_layout()\n",
    "                    print(f\"Saving {filename}...\")\n",
    "                    plt.savefig(filename)\n",
    "                    plt.close()\n",
    "\n",
    "                    # Plot Cost Change\n",
    "                    plt.figure(figsize=(8, 4))\n",
    "                    plt.plot(k_list, cost_mean_list, 'k')\n",
    "                    plt.plot(k_list, np.array(cost_mean_list) + np.array(cost_std_list), 'k--')\n",
    "                    plt.plot(k_list, np.array(cost_mean_list) - np.array(cost_std_list), 'k--')\n",
    "                    plt.xlim([min(k_list), max(k_list)])\n",
    "                    plt.xlabel('Iteration $k$')\n",
    "                    plt.ylabel('Cost change')\n",
    "                    plt.title(f'{N} nodes, {V} RV' + ('' if V == 1 else 's'))\n",
    "                    filename = f'output/cost_stats_{N}_{V}{suffix}.pdf'\n",
    "                    plt.tight_layout()\n",
    "                    print(f\"Saving {filename}...\")\n",
    "                    plt.savefig(filename)\n",
    "                    plt.close()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to generate graph for N={N}, V={V}, suffix={suffix}\")\n",
    "                    print(f\"Exception: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_fleet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
